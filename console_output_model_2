I1205 21:13:19.926515  1846 caffe.cpp:217] Using GPUs 0
I1205 21:13:19.961905  1846 caffe.cpp:222] GPU 0: NVIDIA Tegra X1
I1205 21:13:20.792922  1846 solver.cpp:60] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 20000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1205 21:13:20.793994  1846 solver.cpp:103] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I1205 21:13:20.794796  1846 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1205 21:13:20.794909  1846 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1205 21:13:20.794993  1846 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1205 21:13:20.798377  1846 layer_factory.hpp:77] Creating layer mnist
I1205 21:13:20.799859  1846 net.cpp:100] Creating Layer mnist
I1205 21:13:20.799952  1846 net.cpp:408] mnist -> data
I1205 21:13:20.800092  1846 net.cpp:408] mnist -> label
I1205 21:13:20.801601  1854 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1205 21:13:20.910065  1846 data_layer.cpp:41] output data size: 64,1,28,28
I1205 21:13:20.913354  1846 net.cpp:150] Setting up mnist
I1205 21:13:20.913422  1846 net.cpp:157] Top shape: 64 1 28 28 (50176)
I1205 21:13:20.913487  1846 net.cpp:157] Top shape: 64 (64)
I1205 21:13:20.913527  1846 net.cpp:165] Memory required for data: 200960
I1205 21:13:20.913573  1846 layer_factory.hpp:77] Creating layer conv1
I1205 21:13:20.913657  1846 net.cpp:100] Creating Layer conv1
I1205 21:13:20.913704  1846 net.cpp:434] conv1 <- data
I1205 21:13:20.913758  1846 net.cpp:408] conv1 -> conv1
I1205 21:13:22.234319  1846 net.cpp:150] Setting up conv1
I1205 21:13:22.234401  1846 net.cpp:157] Top shape: 64 20 24 24 (737280)
I1205 21:13:22.234452  1846 net.cpp:165] Memory required for data: 3150080
I1205 21:13:22.234526  1846 layer_factory.hpp:77] Creating layer pool1
I1205 21:13:22.234581  1846 net.cpp:100] Creating Layer pool1
I1205 21:13:22.234678  1846 net.cpp:434] pool1 <- conv1
I1205 21:13:22.234721  1846 net.cpp:408] pool1 -> pool1
I1205 21:13:22.234896  1846 net.cpp:150] Setting up pool1
I1205 21:13:22.234935  1846 net.cpp:157] Top shape: 64 20 12 12 (184320)
I1205 21:13:22.234974  1846 net.cpp:165] Memory required for data: 3887360
I1205 21:13:22.235008  1846 layer_factory.hpp:77] Creating layer conv2
I1205 21:13:22.235059  1846 net.cpp:100] Creating Layer conv2
I1205 21:13:22.235090  1846 net.cpp:434] conv2 <- pool1
I1205 21:13:22.235128  1846 net.cpp:408] conv2 -> conv2
I1205 21:13:22.240759  1846 net.cpp:150] Setting up conv2
I1205 21:13:22.240825  1846 net.cpp:157] Top shape: 64 50 8 8 (204800)
I1205 21:13:22.240871  1846 net.cpp:165] Memory required for data: 4706560
I1205 21:13:22.240921  1846 layer_factory.hpp:77] Creating layer pool2
I1205 21:13:22.240967  1846 net.cpp:100] Creating Layer pool2
I1205 21:13:22.241001  1846 net.cpp:434] pool2 <- conv2
I1205 21:13:22.241040  1846 net.cpp:408] pool2 -> pool2
I1205 21:13:22.241189  1846 net.cpp:150] Setting up pool2
I1205 21:13:22.241225  1846 net.cpp:157] Top shape: 64 50 4 4 (51200)
I1205 21:13:22.241261  1846 net.cpp:165] Memory required for data: 4911360
I1205 21:13:22.241293  1846 layer_factory.hpp:77] Creating layer ip1
I1205 21:13:22.241341  1846 net.cpp:100] Creating Layer ip1
I1205 21:13:22.241375  1846 net.cpp:434] ip1 <- pool2
I1205 21:13:22.241415  1846 net.cpp:408] ip1 -> ip1
I1205 21:13:22.247149  1846 net.cpp:150] Setting up ip1
I1205 21:13:22.247210  1846 net.cpp:157] Top shape: 64 500 (32000)
I1205 21:13:22.247249  1846 net.cpp:165] Memory required for data: 5039360
I1205 21:13:22.247305  1846 layer_factory.hpp:77] Creating layer relu1
I1205 21:13:22.247359  1846 net.cpp:100] Creating Layer relu1
I1205 21:13:22.247398  1846 net.cpp:434] relu1 <- ip1
I1205 21:13:22.247438  1846 net.cpp:395] relu1 -> ip1 (in-place)
I1205 21:13:22.249629  1846 net.cpp:150] Setting up relu1
I1205 21:13:22.249704  1846 net.cpp:157] Top shape: 64 500 (32000)
I1205 21:13:22.249743  1846 net.cpp:165] Memory required for data: 5167360
I1205 21:13:22.249778  1846 layer_factory.hpp:77] Creating layer ip2
I1205 21:13:22.249825  1846 net.cpp:100] Creating Layer ip2
I1205 21:13:22.249862  1846 net.cpp:434] ip2 <- ip1
I1205 21:13:22.249907  1846 net.cpp:408] ip2 -> ip2
I1205 21:13:22.250830  1846 net.cpp:150] Setting up ip2
I1205 21:13:22.250893  1846 net.cpp:157] Top shape: 64 10 (640)
I1205 21:13:22.250931  1846 net.cpp:165] Memory required for data: 5169920
I1205 21:13:22.250977  1846 layer_factory.hpp:77] Creating layer loss
I1205 21:13:22.251032  1846 net.cpp:100] Creating Layer loss
I1205 21:13:22.251070  1846 net.cpp:434] loss <- ip2
I1205 21:13:22.251114  1846 net.cpp:434] loss <- label
I1205 21:13:22.251154  1846 net.cpp:408] loss -> loss
I1205 21:13:22.251232  1846 layer_factory.hpp:77] Creating layer loss
I1205 21:13:22.253334  1846 net.cpp:150] Setting up loss
I1205 21:13:22.253392  1846 net.cpp:157] Top shape: (1)
I1205 21:13:22.253437  1846 net.cpp:160]     with loss weight 1
I1205 21:13:22.253510  1846 net.cpp:165] Memory required for data: 5169924
I1205 21:13:22.253547  1846 net.cpp:226] loss needs backward computation.
I1205 21:13:22.253594  1846 net.cpp:226] ip2 needs backward computation.
I1205 21:13:22.253631  1846 net.cpp:226] relu1 needs backward computation.
I1205 21:13:22.253665  1846 net.cpp:226] ip1 needs backward computation.
I1205 21:13:22.253695  1846 net.cpp:226] pool2 needs backward computation.
I1205 21:13:22.253728  1846 net.cpp:226] conv2 needs backward computation.
I1205 21:13:22.253759  1846 net.cpp:226] pool1 needs backward computation.
I1205 21:13:22.253793  1846 net.cpp:226] conv1 needs backward computation.
I1205 21:13:22.253911  1846 net.cpp:228] mnist does not need backward computation.
I1205 21:13:22.253945  1846 net.cpp:270] This network produces output loss
I1205 21:13:22.253993  1846 net.cpp:283] Network initialization done.
I1205 21:13:22.254441  1846 solver.cpp:193] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1205 21:13:22.254588  1846 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1205 21:13:22.254644  1846 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1205 21:13:22.257349  1846 layer_factory.hpp:77] Creating layer mnist
I1205 21:13:22.257623  1846 net.cpp:100] Creating Layer mnist
I1205 21:13:22.257678  1846 net.cpp:408] mnist -> data
I1205 21:13:22.257730  1846 net.cpp:408] mnist -> label
I1205 21:13:22.258893  1856 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1205 21:13:22.259246  1846 data_layer.cpp:41] output data size: 100,1,28,28
I1205 21:13:22.281072  1846 net.cpp:150] Setting up mnist
I1205 21:13:22.281150  1846 net.cpp:157] Top shape: 100 1 28 28 (78400)
I1205 21:13:22.281199  1846 net.cpp:157] Top shape: 100 (100)
I1205 21:13:22.281253  1846 net.cpp:165] Memory required for data: 314000
I1205 21:13:22.281293  1846 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1205 21:13:22.281347  1846 net.cpp:100] Creating Layer label_mnist_1_split
I1205 21:13:22.281383  1846 net.cpp:434] label_mnist_1_split <- label
I1205 21:13:22.281431  1846 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I1205 21:13:22.281486  1846 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I1205 21:13:22.281765  1846 net.cpp:150] Setting up label_mnist_1_split
I1205 21:13:22.281812  1846 net.cpp:157] Top shape: 100 (100)
I1205 21:13:22.281852  1846 net.cpp:157] Top shape: 100 (100)
I1205 21:13:22.281883  1846 net.cpp:165] Memory required for data: 314800
I1205 21:13:22.281918  1846 layer_factory.hpp:77] Creating layer conv1
I1205 21:13:22.281971  1846 net.cpp:100] Creating Layer conv1
I1205 21:13:22.282001  1846 net.cpp:434] conv1 <- data
I1205 21:13:22.282043  1846 net.cpp:408] conv1 -> conv1
I1205 21:13:22.289158  1846 net.cpp:150] Setting up conv1
I1205 21:13:22.289221  1846 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I1205 21:13:22.289275  1846 net.cpp:165] Memory required for data: 4922800
I1205 21:13:22.289327  1846 layer_factory.hpp:77] Creating layer pool1
I1205 21:13:22.289430  1846 net.cpp:100] Creating Layer pool1
I1205 21:13:22.289463  1846 net.cpp:434] pool1 <- conv1
I1205 21:13:22.289511  1846 net.cpp:408] pool1 -> pool1
I1205 21:13:22.289705  1846 net.cpp:150] Setting up pool1
I1205 21:13:22.289746  1846 net.cpp:157] Top shape: 100 20 12 12 (288000)
I1205 21:13:22.289786  1846 net.cpp:165] Memory required for data: 6074800
I1205 21:13:22.289816  1846 layer_factory.hpp:77] Creating layer conv2
I1205 21:13:22.289877  1846 net.cpp:100] Creating Layer conv2
I1205 21:13:22.289911  1846 net.cpp:434] conv2 <- pool1
I1205 21:13:22.289952  1846 net.cpp:408] conv2 -> conv2
I1205 21:13:22.296669  1846 net.cpp:150] Setting up conv2
I1205 21:13:22.296816  1846 net.cpp:157] Top shape: 100 50 8 8 (320000)
I1205 21:13:22.296867  1846 net.cpp:165] Memory required for data: 7354800
I1205 21:13:22.296921  1846 layer_factory.hpp:77] Creating layer pool2
I1205 21:13:22.296977  1846 net.cpp:100] Creating Layer pool2
I1205 21:13:22.297014  1846 net.cpp:434] pool2 <- conv2
I1205 21:13:22.297056  1846 net.cpp:408] pool2 -> pool2
I1205 21:13:22.297269  1846 net.cpp:150] Setting up pool2
I1205 21:13:22.297313  1846 net.cpp:157] Top shape: 100 50 4 4 (80000)
I1205 21:13:22.297350  1846 net.cpp:165] Memory required for data: 7674800
I1205 21:13:22.297382  1846 layer_factory.hpp:77] Creating layer ip1
I1205 21:13:22.297487  1846 net.cpp:100] Creating Layer ip1
I1205 21:13:22.297523  1846 net.cpp:434] ip1 <- pool2
I1205 21:13:22.297567  1846 net.cpp:408] ip1 -> ip1
I1205 21:13:22.303365  1846 net.cpp:150] Setting up ip1
I1205 21:13:22.303427  1846 net.cpp:157] Top shape: 100 500 (50000)
I1205 21:13:22.303464  1846 net.cpp:165] Memory required for data: 7874800
I1205 21:13:22.303510  1846 layer_factory.hpp:77] Creating layer relu1
I1205 21:13:22.303550  1846 net.cpp:100] Creating Layer relu1
I1205 21:13:22.303580  1846 net.cpp:434] relu1 <- ip1
I1205 21:13:22.303616  1846 net.cpp:395] relu1 -> ip1 (in-place)
I1205 21:13:22.305483  1846 net.cpp:150] Setting up relu1
I1205 21:13:22.305544  1846 net.cpp:157] Top shape: 100 500 (50000)
I1205 21:13:22.305583  1846 net.cpp:165] Memory required for data: 8074800
I1205 21:13:22.305618  1846 layer_factory.hpp:77] Creating layer ip2
I1205 21:13:22.305680  1846 net.cpp:100] Creating Layer ip2
I1205 21:13:22.305717  1846 net.cpp:434] ip2 <- ip1
I1205 21:13:22.305760  1846 net.cpp:408] ip2 -> ip2
I1205 21:13:22.306347  1846 net.cpp:150] Setting up ip2
I1205 21:13:22.306401  1846 net.cpp:157] Top shape: 100 10 (1000)
I1205 21:13:22.306437  1846 net.cpp:165] Memory required for data: 8078800
I1205 21:13:22.306475  1846 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1205 21:13:22.306515  1846 net.cpp:100] Creating Layer ip2_ip2_0_split
I1205 21:13:22.306545  1846 net.cpp:434] ip2_ip2_0_split <- ip2
I1205 21:13:22.306587  1846 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1205 21:13:22.306628  1846 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1205 21:13:22.306788  1846 net.cpp:150] Setting up ip2_ip2_0_split
I1205 21:13:22.306823  1846 net.cpp:157] Top shape: 100 10 (1000)
I1205 21:13:22.306855  1846 net.cpp:157] Top shape: 100 10 (1000)
I1205 21:13:22.306885  1846 net.cpp:165] Memory required for data: 8086800
I1205 21:13:22.306913  1846 layer_factory.hpp:77] Creating layer accuracy
I1205 21:13:22.306958  1846 net.cpp:100] Creating Layer accuracy
I1205 21:13:22.306989  1846 net.cpp:434] accuracy <- ip2_ip2_0_split_0
I1205 21:13:22.307021  1846 net.cpp:434] accuracy <- label_mnist_1_split_0
I1205 21:13:22.307061  1846 net.cpp:408] accuracy -> accuracy
I1205 21:13:22.307128  1846 net.cpp:150] Setting up accuracy
I1205 21:13:22.307163  1846 net.cpp:157] Top shape: (1)
I1205 21:13:22.307195  1846 net.cpp:165] Memory required for data: 8086804
I1205 21:13:22.307224  1846 layer_factory.hpp:77] Creating layer loss
I1205 21:13:22.307257  1846 net.cpp:100] Creating Layer loss
I1205 21:13:22.307298  1846 net.cpp:434] loss <- ip2_ip2_0_split_1
I1205 21:13:22.307330  1846 net.cpp:434] loss <- label_mnist_1_split_1
I1205 21:13:22.307432  1846 net.cpp:408] loss -> loss
I1205 21:13:22.307479  1846 layer_factory.hpp:77] Creating layer loss
I1205 21:13:22.309641  1846 net.cpp:150] Setting up loss
I1205 21:13:22.309698  1846 net.cpp:157] Top shape: (1)
I1205 21:13:22.309739  1846 net.cpp:160]     with loss weight 1
I1205 21:13:22.309777  1846 net.cpp:165] Memory required for data: 8086808
I1205 21:13:22.309808  1846 net.cpp:226] loss needs backward computation.
I1205 21:13:22.309840  1846 net.cpp:228] accuracy does not need backward computation.
I1205 21:13:22.309870  1846 net.cpp:226] ip2_ip2_0_split needs backward computation.
I1205 21:13:22.309900  1846 net.cpp:226] ip2 needs backward computation.
I1205 21:13:22.309926  1846 net.cpp:226] relu1 needs backward computation.
I1205 21:13:22.309952  1846 net.cpp:226] ip1 needs backward computation.
I1205 21:13:22.309981  1846 net.cpp:226] pool2 needs backward computation.
I1205 21:13:22.310009  1846 net.cpp:226] conv2 needs backward computation.
I1205 21:13:22.310037  1846 net.cpp:226] pool1 needs backward computation.
I1205 21:13:22.310067  1846 net.cpp:226] conv1 needs backward computation.
I1205 21:13:22.310097  1846 net.cpp:228] label_mnist_1_split does not need backward computation.
I1205 21:13:22.310127  1846 net.cpp:228] mnist does not need backward computation.
I1205 21:13:22.310154  1846 net.cpp:270] This network produces output accuracy
I1205 21:13:22.310184  1846 net.cpp:270] This network produces output loss
I1205 21:13:22.310235  1846 net.cpp:283] Network initialization done.
I1205 21:13:22.310392  1846 solver.cpp:72] Solver scaffolding done.
I1205 21:13:22.311435  1846 caffe.cpp:251] Starting Optimization
I1205 21:13:22.311478  1846 solver.cpp:291] Solving LeNet
I1205 21:13:22.311508  1846 solver.cpp:292] Learning Rate Policy: inv
I1205 21:13:22.314045  1846 solver.cpp:349] Iteration 0, Testing net (#0)
I1205 21:13:22.984498  1846 solver.cpp:416]     Test net output #0: accuracy = 0.0895
I1205 21:13:22.984599  1846 solver.cpp:416]     Test net output #1: loss = 2.35978 (* 1 = 2.35978 loss)
I1205 21:13:23.000149  1846 solver.cpp:240] Iteration 0, loss = 2.37641
I1205 21:13:23.000250  1846 solver.cpp:256]     Train net output #0: loss = 2.37641 (* 1 = 2.37641 loss)
I1205 21:13:23.000339  1846 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1205 21:13:24.542662  1846 solver.cpp:240] Iteration 100, loss = 0.218732
I1205 21:13:24.542831  1846 solver.cpp:256]     Train net output #0: loss = 0.218732 (* 1 = 0.218732 loss)
I1205 21:13:24.542930  1846 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I1205 21:13:26.119357  1846 solver.cpp:240] Iteration 200, loss = 0.147778
I1205 21:13:26.119506  1846 solver.cpp:256]     Train net output #0: loss = 0.147778 (* 1 = 0.147778 loss)
I1205 21:13:26.119616  1846 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I1205 21:13:27.687798  1846 solver.cpp:240] Iteration 300, loss = 0.197839
I1205 21:13:27.687949  1846 solver.cpp:256]     Train net output #0: loss = 0.197839 (* 1 = 0.197839 loss)
I1205 21:13:27.688041  1846 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I1205 21:13:29.271534  1846 solver.cpp:240] Iteration 400, loss = 0.0680657
I1205 21:13:29.271657  1846 solver.cpp:256]     Train net output #0: loss = 0.0680657 (* 1 = 0.0680657 loss)
I1205 21:13:29.271744  1846 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I1205 21:13:30.832317  1846 solver.cpp:349] Iteration 500, Testing net (#0)
I1205 21:13:31.599413  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9732
I1205 21:13:31.599747  1846 solver.cpp:416]     Test net output #1: loss = 0.0859866 (* 1 = 0.0859866 loss)
I1205 21:13:31.608211  1846 solver.cpp:240] Iteration 500, loss = 0.0818521
I1205 21:13:31.608557  1846 solver.cpp:256]     Train net output #0: loss = 0.0818521 (* 1 = 0.0818521 loss)
I1205 21:13:31.608768  1846 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I1205 21:13:33.250921  1846 solver.cpp:240] Iteration 600, loss = 0.098665
I1205 21:13:33.251102  1846 solver.cpp:256]     Train net output #0: loss = 0.098665 (* 1 = 0.098665 loss)
I1205 21:13:33.251351  1846 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I1205 21:13:34.782744  1846 solver.cpp:240] Iteration 700, loss = 0.10918
I1205 21:13:34.782902  1846 solver.cpp:256]     Train net output #0: loss = 0.109181 (* 1 = 0.109181 loss)
I1205 21:13:34.782999  1846 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I1205 21:13:36.335083  1846 solver.cpp:240] Iteration 800, loss = 0.219698
I1205 21:13:36.335244  1846 solver.cpp:256]     Train net output #0: loss = 0.219698 (* 1 = 0.219698 loss)
I1205 21:13:36.335348  1846 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I1205 21:13:37.882499  1846 solver.cpp:240] Iteration 900, loss = 0.167421
I1205 21:13:37.882658  1846 solver.cpp:256]     Train net output #0: loss = 0.167421 (* 1 = 0.167421 loss)
I1205 21:13:37.882762  1846 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I1205 21:13:39.410334  1846 solver.cpp:349] Iteration 1000, Testing net (#0)
I1205 21:13:39.949568  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9791
I1205 21:13:39.949865  1846 solver.cpp:416]     Test net output #1: loss = 0.0618831 (* 1 = 0.0618831 loss)
I1205 21:13:39.955673  1846 solver.cpp:240] Iteration 1000, loss = 0.08662
I1205 21:13:39.955915  1846 solver.cpp:256]     Train net output #0: loss = 0.0866201 (* 1 = 0.0866201 loss)
I1205 21:13:39.956091  1846 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I1205 21:13:41.548971  1846 solver.cpp:240] Iteration 1100, loss = 0.0103155
I1205 21:13:41.549367  1846 solver.cpp:256]     Train net output #0: loss = 0.0103155 (* 1 = 0.0103155 loss)
I1205 21:13:41.549628  1846 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I1205 21:13:43.120846  1846 solver.cpp:240] Iteration 1200, loss = 0.0234254
I1205 21:13:43.120985  1846 solver.cpp:256]     Train net output #0: loss = 0.0234254 (* 1 = 0.0234254 loss)
I1205 21:13:43.121076  1846 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I1205 21:13:44.705118  1846 solver.cpp:240] Iteration 1300, loss = 0.0275611
I1205 21:13:44.705261  1846 solver.cpp:256]     Train net output #0: loss = 0.0275611 (* 1 = 0.0275611 loss)
I1205 21:13:44.705359  1846 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I1205 21:13:46.274485  1846 solver.cpp:240] Iteration 1400, loss = 0.00453982
I1205 21:13:46.274646  1846 solver.cpp:256]     Train net output #0: loss = 0.0045398 (* 1 = 0.0045398 loss)
I1205 21:13:46.274765  1846 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I1205 21:13:47.796777  1846 solver.cpp:349] Iteration 1500, Testing net (#0)
I1205 21:13:48.335196  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9843
I1205 21:13:48.335554  1846 solver.cpp:416]     Test net output #1: loss = 0.0493972 (* 1 = 0.0493972 loss)
I1205 21:13:48.344111  1846 solver.cpp:240] Iteration 1500, loss = 0.0818186
I1205 21:13:48.344233  1846 solver.cpp:256]     Train net output #0: loss = 0.0818186 (* 1 = 0.0818186 loss)
I1205 21:13:48.344326  1846 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I1205 21:13:49.940454  1846 solver.cpp:240] Iteration 1600, loss = 0.110842
I1205 21:13:49.941241  1846 solver.cpp:256]     Train net output #0: loss = 0.110842 (* 1 = 0.110842 loss)
I1205 21:13:49.941370  1846 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I1205 21:13:51.545184  1846 solver.cpp:240] Iteration 1700, loss = 0.0551776
I1205 21:13:51.545354  1846 solver.cpp:256]     Train net output #0: loss = 0.0551776 (* 1 = 0.0551776 loss)
I1205 21:13:51.545473  1846 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I1205 21:13:53.129477  1846 solver.cpp:240] Iteration 1800, loss = 0.0158016
I1205 21:13:53.129624  1846 solver.cpp:256]     Train net output #0: loss = 0.0158016 (* 1 = 0.0158016 loss)
I1205 21:13:53.129720  1846 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I1205 21:13:54.694458  1846 solver.cpp:240] Iteration 1900, loss = 0.133286
I1205 21:13:54.694893  1846 solver.cpp:256]     Train net output #0: loss = 0.133286 (* 1 = 0.133286 loss)
I1205 21:13:54.695186  1846 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I1205 21:13:56.208616  1846 solver.cpp:349] Iteration 2000, Testing net (#0)
I1205 21:13:56.862987  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9869
I1205 21:13:56.863343  1846 solver.cpp:416]     Test net output #1: loss = 0.0420604 (* 1 = 0.0420604 loss)
I1205 21:13:56.869654  1846 solver.cpp:240] Iteration 2000, loss = 0.0130494
I1205 21:13:56.869995  1846 solver.cpp:256]     Train net output #0: loss = 0.0130494 (* 1 = 0.0130494 loss)
I1205 21:13:56.870234  1846 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I1205 21:13:58.447371  1846 solver.cpp:240] Iteration 2100, loss = 0.0203609
I1205 21:13:58.447526  1846 solver.cpp:256]     Train net output #0: loss = 0.0203608 (* 1 = 0.0203608 loss)
I1205 21:13:58.447609  1846 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I1205 21:14:00.027487  1846 solver.cpp:240] Iteration 2200, loss = 0.0141851
I1205 21:14:00.027606  1846 solver.cpp:256]     Train net output #0: loss = 0.0141851 (* 1 = 0.0141851 loss)
I1205 21:14:00.027675  1846 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I1205 21:14:01.564545  1846 solver.cpp:240] Iteration 2300, loss = 0.0565746
I1205 21:14:01.564719  1846 solver.cpp:256]     Train net output #0: loss = 0.0565746 (* 1 = 0.0565746 loss)
I1205 21:14:01.564816  1846 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I1205 21:14:03.090600  1846 solver.cpp:240] Iteration 2400, loss = 0.00863431
I1205 21:14:03.090768  1846 solver.cpp:256]     Train net output #0: loss = 0.0086343 (* 1 = 0.0086343 loss)
I1205 21:14:03.090880  1846 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I1205 21:14:04.606850  1846 solver.cpp:349] Iteration 2500, Testing net (#0)
I1205 21:14:05.126304  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9829
I1205 21:14:05.126405  1846 solver.cpp:416]     Test net output #1: loss = 0.0534798 (* 1 = 0.0534798 loss)
I1205 21:14:05.131897  1846 solver.cpp:240] Iteration 2500, loss = 0.0232048
I1205 21:14:05.131996  1846 solver.cpp:256]     Train net output #0: loss = 0.0232048 (* 1 = 0.0232048 loss)
I1205 21:14:05.132055  1846 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I1205 21:14:06.701663  1846 solver.cpp:240] Iteration 2600, loss = 0.0605552
I1205 21:14:06.701853  1846 solver.cpp:256]     Train net output #0: loss = 0.0605552 (* 1 = 0.0605552 loss)
I1205 21:14:06.701987  1846 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I1205 21:14:08.246883  1846 solver.cpp:240] Iteration 2700, loss = 0.0528453
I1205 21:14:08.247046  1846 solver.cpp:256]     Train net output #0: loss = 0.0528453 (* 1 = 0.0528453 loss)
I1205 21:14:08.247176  1846 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I1205 21:14:09.787511  1846 solver.cpp:240] Iteration 2800, loss = 0.00306818
I1205 21:14:09.787678  1846 solver.cpp:256]     Train net output #0: loss = 0.00306816 (* 1 = 0.00306816 loss)
I1205 21:14:09.787773  1846 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I1205 21:14:11.329675  1846 solver.cpp:240] Iteration 2900, loss = 0.0246241
I1205 21:14:11.329831  1846 solver.cpp:256]     Train net output #0: loss = 0.024624 (* 1 = 0.024624 loss)
I1205 21:14:11.330062  1846 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I1205 21:14:12.844344  1846 solver.cpp:349] Iteration 3000, Testing net (#0)
I1205 21:14:13.370386  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9867
I1205 21:14:13.370517  1846 solver.cpp:416]     Test net output #1: loss = 0.0387067 (* 1 = 0.0387067 loss)
I1205 21:14:13.375783  1846 solver.cpp:240] Iteration 3000, loss = 0.0145264
I1205 21:14:13.375902  1846 solver.cpp:256]     Train net output #0: loss = 0.0145264 (* 1 = 0.0145264 loss)
I1205 21:14:13.375993  1846 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I1205 21:14:14.910878  1846 solver.cpp:240] Iteration 3100, loss = 0.0487707
I1205 21:14:14.911029  1846 solver.cpp:256]     Train net output #0: loss = 0.0487707 (* 1 = 0.0487707 loss)
I1205 21:14:14.911113  1846 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I1205 21:14:16.448237  1846 solver.cpp:240] Iteration 3200, loss = 0.00591091
I1205 21:14:16.448674  1846 solver.cpp:256]     Train net output #0: loss = 0.00591089 (* 1 = 0.00591089 loss)
I1205 21:14:16.448974  1846 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I1205 21:14:17.985044  1846 solver.cpp:240] Iteration 3300, loss = 0.0409284
I1205 21:14:17.985206  1846 solver.cpp:256]     Train net output #0: loss = 0.0409284 (* 1 = 0.0409284 loss)
I1205 21:14:17.985308  1846 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I1205 21:14:19.516072  1846 solver.cpp:240] Iteration 3400, loss = 0.0135064
I1205 21:14:19.516237  1846 solver.cpp:256]     Train net output #0: loss = 0.0135064 (* 1 = 0.0135064 loss)
I1205 21:14:19.516373  1846 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I1205 21:14:21.042815  1846 solver.cpp:349] Iteration 3500, Testing net (#0)
I1205 21:14:21.574463  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9853
I1205 21:14:21.574595  1846 solver.cpp:416]     Test net output #1: loss = 0.0457494 (* 1 = 0.0457494 loss)
I1205 21:14:21.580039  1846 solver.cpp:240] Iteration 3500, loss = 0.00498974
I1205 21:14:21.580155  1846 solver.cpp:256]     Train net output #0: loss = 0.00498973 (* 1 = 0.00498973 loss)
I1205 21:14:21.580238  1846 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I1205 21:14:23.181032  1846 solver.cpp:240] Iteration 3600, loss = 0.029007
I1205 21:14:23.181483  1846 solver.cpp:256]     Train net output #0: loss = 0.029007 (* 1 = 0.029007 loss)
I1205 21:14:23.181778  1846 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I1205 21:14:24.747403  1846 solver.cpp:240] Iteration 3700, loss = 0.0143973
I1205 21:14:24.747571  1846 solver.cpp:256]     Train net output #0: loss = 0.0143973 (* 1 = 0.0143973 loss)
I1205 21:14:24.747668  1846 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I1205 21:14:26.279083  1846 solver.cpp:240] Iteration 3800, loss = 0.0141934
I1205 21:14:26.279261  1846 solver.cpp:256]     Train net output #0: loss = 0.0141934 (* 1 = 0.0141934 loss)
I1205 21:14:26.279374  1846 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I1205 21:14:27.849267  1846 solver.cpp:240] Iteration 3900, loss = 0.0158427
I1205 21:14:27.849424  1846 solver.cpp:256]     Train net output #0: loss = 0.0158426 (* 1 = 0.0158426 loss)
I1205 21:14:27.849531  1846 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I1205 21:14:29.409219  1846 solver.cpp:349] Iteration 4000, Testing net (#0)
I1205 21:14:29.953308  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9893
I1205 21:14:29.953413  1846 solver.cpp:416]     Test net output #1: loss = 0.0325891 (* 1 = 0.0325891 loss)
I1205 21:14:29.959024  1846 solver.cpp:240] Iteration 4000, loss = 0.019165
I1205 21:14:29.959137  1846 solver.cpp:256]     Train net output #0: loss = 0.0191649 (* 1 = 0.0191649 loss)
I1205 21:14:29.959214  1846 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I1205 21:14:31.519268  1846 solver.cpp:240] Iteration 4100, loss = 0.0202408
I1205 21:14:31.519430  1846 solver.cpp:256]     Train net output #0: loss = 0.0202408 (* 1 = 0.0202408 loss)
I1205 21:14:31.519536  1846 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I1205 21:14:33.040328  1846 solver.cpp:240] Iteration 4200, loss = 0.0122572
I1205 21:14:33.042278  1846 solver.cpp:256]     Train net output #0: loss = 0.0122572 (* 1 = 0.0122572 loss)
I1205 21:14:33.042546  1846 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I1205 21:14:34.649976  1846 solver.cpp:240] Iteration 4300, loss = 0.0415518
I1205 21:14:34.650522  1846 solver.cpp:256]     Train net output #0: loss = 0.0415517 (* 1 = 0.0415517 loss)
I1205 21:14:34.650818  1846 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I1205 21:14:36.185343  1846 solver.cpp:240] Iteration 4400, loss = 0.0266804
I1205 21:14:36.185511  1846 solver.cpp:256]     Train net output #0: loss = 0.0266804 (* 1 = 0.0266804 loss)
I1205 21:14:36.185626  1846 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I1205 21:14:37.707345  1846 solver.cpp:349] Iteration 4500, Testing net (#0)
I1205 21:14:38.220584  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9887
I1205 21:14:38.220681  1846 solver.cpp:416]     Test net output #1: loss = 0.0351682 (* 1 = 0.0351682 loss)
I1205 21:14:38.225477  1846 solver.cpp:240] Iteration 4500, loss = 0.00658922
I1205 21:14:38.225558  1846 solver.cpp:256]     Train net output #0: loss = 0.00658919 (* 1 = 0.00658919 loss)
I1205 21:14:38.225610  1846 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I1205 21:14:39.766212  1846 solver.cpp:240] Iteration 4600, loss = 0.0143739
I1205 21:14:39.766400  1846 solver.cpp:256]     Train net output #0: loss = 0.0143739 (* 1 = 0.0143739 loss)
I1205 21:14:39.766523  1846 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I1205 21:14:41.314055  1846 solver.cpp:240] Iteration 4700, loss = 0.0063791
I1205 21:14:41.314220  1846 solver.cpp:256]     Train net output #0: loss = 0.00637907 (* 1 = 0.00637907 loss)
I1205 21:14:41.314461  1846 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I1205 21:14:42.854873  1846 solver.cpp:240] Iteration 4800, loss = 0.0113522
I1205 21:14:42.855021  1846 solver.cpp:256]     Train net output #0: loss = 0.0113521 (* 1 = 0.0113521 loss)
I1205 21:14:42.855105  1846 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I1205 21:14:44.375550  1846 solver.cpp:240] Iteration 4900, loss = 0.00375374
I1205 21:14:44.375696  1846 solver.cpp:256]     Train net output #0: loss = 0.0037537 (* 1 = 0.0037537 loss)
I1205 21:14:44.375782  1846 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I1205 21:14:45.888830  1846 solver.cpp:466] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I1205 21:14:45.952564  1846 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I1205 21:14:45.964241  1846 solver.cpp:349] Iteration 5000, Testing net (#0)
I1205 21:14:46.513044  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9892
I1205 21:14:46.513200  1846 solver.cpp:416]     Test net output #1: loss = 0.0327984 (* 1 = 0.0327984 loss)
I1205 21:14:46.518048  1846 solver.cpp:240] Iteration 5000, loss = 0.0233897
I1205 21:14:46.518141  1846 solver.cpp:256]     Train net output #0: loss = 0.0233897 (* 1 = 0.0233897 loss)
I1205 21:14:46.518198  1846 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I1205 21:14:48.042697  1846 solver.cpp:240] Iteration 5100, loss = 0.0189851
I1205 21:14:48.042867  1846 solver.cpp:256]     Train net output #0: loss = 0.018985 (* 1 = 0.018985 loss)
I1205 21:14:48.042976  1846 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I1205 21:14:49.574522  1846 solver.cpp:240] Iteration 5200, loss = 0.00849246
I1205 21:14:49.574694  1846 solver.cpp:256]     Train net output #0: loss = 0.00849242 (* 1 = 0.00849242 loss)
I1205 21:14:49.574807  1846 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I1205 21:14:51.111555  1846 solver.cpp:240] Iteration 5300, loss = 0.00171589
I1205 21:14:51.112201  1846 solver.cpp:256]     Train net output #0: loss = 0.00171585 (* 1 = 0.00171585 loss)
I1205 21:14:51.112306  1846 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I1205 21:14:52.640832  1846 solver.cpp:240] Iteration 5400, loss = 0.0104425
I1205 21:14:52.640995  1846 solver.cpp:256]     Train net output #0: loss = 0.0104424 (* 1 = 0.0104424 loss)
I1205 21:14:52.641116  1846 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I1205 21:14:54.156656  1846 solver.cpp:349] Iteration 5500, Testing net (#0)
I1205 21:14:54.733477  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9894
I1205 21:14:54.733841  1846 solver.cpp:416]     Test net output #1: loss = 0.0341716 (* 1 = 0.0341716 loss)
I1205 21:14:54.739255  1846 solver.cpp:240] Iteration 5500, loss = 0.00929723
I1205 21:14:54.739573  1846 solver.cpp:256]     Train net output #0: loss = 0.00929717 (* 1 = 0.00929717 loss)
I1205 21:14:54.739806  1846 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I1205 21:14:56.333209  1846 solver.cpp:240] Iteration 5600, loss = 0.00131615
I1205 21:14:56.333384  1846 solver.cpp:256]     Train net output #0: loss = 0.00131608 (* 1 = 0.00131608 loss)
I1205 21:14:56.333484  1846 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I1205 21:14:57.878743  1846 solver.cpp:240] Iteration 5700, loss = 0.0032427
I1205 21:14:57.878912  1846 solver.cpp:256]     Train net output #0: loss = 0.00324264 (* 1 = 0.00324264 loss)
I1205 21:14:57.879014  1846 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I1205 21:14:59.413097  1846 solver.cpp:240] Iteration 5800, loss = 0.0304004
I1205 21:14:59.413264  1846 solver.cpp:256]     Train net output #0: loss = 0.0304004 (* 1 = 0.0304004 loss)
I1205 21:14:59.413383  1846 sgd_solver.cpp:106] Iteration 5800, lr = 0.00709589
I1205 21:15:00.955060  1846 solver.cpp:240] Iteration 5900, loss = 0.00686576
I1205 21:15:00.955231  1846 solver.cpp:256]     Train net output #0: loss = 0.00686568 (* 1 = 0.00686568 loss)
I1205 21:15:00.955330  1846 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I1205 21:15:02.480512  1846 solver.cpp:349] Iteration 6000, Testing net (#0)
I1205 21:15:03.044886  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9909
I1205 21:15:03.045024  1846 solver.cpp:416]     Test net output #1: loss = 0.029409 (* 1 = 0.029409 loss)
I1205 21:15:03.051656  1846 solver.cpp:240] Iteration 6000, loss = 0.00339566
I1205 21:15:03.051782  1846 solver.cpp:256]     Train net output #0: loss = 0.00339558 (* 1 = 0.00339558 loss)
I1205 21:15:03.051882  1846 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I1205 21:15:04.579848  1846 solver.cpp:240] Iteration 6100, loss = 0.00194847
I1205 21:15:04.580016  1846 solver.cpp:256]     Train net output #0: loss = 0.00194837 (* 1 = 0.00194837 loss)
I1205 21:15:04.580116  1846 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I1205 21:15:06.191124  1846 solver.cpp:240] Iteration 6200, loss = 0.00719972
I1205 21:15:06.191289  1846 solver.cpp:256]     Train net output #0: loss = 0.00719962 (* 1 = 0.00719962 loss)
I1205 21:15:06.191387  1846 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I1205 21:15:07.780891  1846 solver.cpp:240] Iteration 6300, loss = 0.00750675
I1205 21:15:07.781085  1846 solver.cpp:256]     Train net output #0: loss = 0.00750666 (* 1 = 0.00750666 loss)
I1205 21:15:07.781203  1846 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I1205 21:15:09.330502  1846 solver.cpp:240] Iteration 6400, loss = 0.0064489
I1205 21:15:09.330663  1846 solver.cpp:256]     Train net output #0: loss = 0.00644881 (* 1 = 0.00644881 loss)
I1205 21:15:09.330781  1846 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I1205 21:15:10.840535  1846 solver.cpp:349] Iteration 6500, Testing net (#0)
I1205 21:15:11.358196  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9901
I1205 21:15:11.358283  1846 solver.cpp:416]     Test net output #1: loss = 0.0326329 (* 1 = 0.0326329 loss)
I1205 21:15:11.363787  1846 solver.cpp:240] Iteration 6500, loss = 0.00813072
I1205 21:15:11.363868  1846 solver.cpp:256]     Train net output #0: loss = 0.00813063 (* 1 = 0.00813063 loss)
I1205 21:15:11.364003  1846 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I1205 21:15:12.995199  1846 solver.cpp:240] Iteration 6600, loss = 0.0256973
I1205 21:15:12.995350  1846 solver.cpp:256]     Train net output #0: loss = 0.0256972 (* 1 = 0.0256972 loss)
I1205 21:15:12.995434  1846 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I1205 21:15:14.577919  1846 solver.cpp:240] Iteration 6700, loss = 0.00996496
I1205 21:15:14.578079  1846 solver.cpp:256]     Train net output #0: loss = 0.00996488 (* 1 = 0.00996488 loss)
I1205 21:15:14.578176  1846 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I1205 21:15:16.102066  1846 solver.cpp:240] Iteration 6800, loss = 0.00396059
I1205 21:15:16.102253  1846 solver.cpp:256]     Train net output #0: loss = 0.00396051 (* 1 = 0.00396051 loss)
I1205 21:15:16.102367  1846 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I1205 21:15:17.641690  1846 solver.cpp:240] Iteration 6900, loss = 0.00453991
I1205 21:15:17.641855  1846 solver.cpp:256]     Train net output #0: loss = 0.00453982 (* 1 = 0.00453982 loss)
I1205 21:15:17.641953  1846 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I1205 21:15:19.178846  1846 solver.cpp:349] Iteration 7000, Testing net (#0)
I1205 21:15:19.725342  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9904
I1205 21:15:19.725432  1846 solver.cpp:416]     Test net output #1: loss = 0.0295542 (* 1 = 0.0295542 loss)
I1205 21:15:19.729981  1846 solver.cpp:240] Iteration 7000, loss = 0.00383684
I1205 21:15:19.730062  1846 solver.cpp:256]     Train net output #0: loss = 0.00383675 (* 1 = 0.00383675 loss)
I1205 21:15:19.730110  1846 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I1205 21:15:21.278484  1846 solver.cpp:240] Iteration 7100, loss = 0.0157938
I1205 21:15:21.279134  1846 solver.cpp:256]     Train net output #0: loss = 0.0157937 (* 1 = 0.0157937 loss)
I1205 21:15:21.279247  1846 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I1205 21:15:22.818189  1846 solver.cpp:240] Iteration 7200, loss = 0.00453245
I1205 21:15:22.818361  1846 solver.cpp:256]     Train net output #0: loss = 0.00453235 (* 1 = 0.00453235 loss)
I1205 21:15:22.818459  1846 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I1205 21:15:24.351887  1846 solver.cpp:240] Iteration 7300, loss = 0.0205376
I1205 21:15:24.352077  1846 solver.cpp:256]     Train net output #0: loss = 0.0205375 (* 1 = 0.0205375 loss)
I1205 21:15:24.352190  1846 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I1205 21:15:25.888850  1846 solver.cpp:240] Iteration 7400, loss = 0.00472375
I1205 21:15:25.889017  1846 solver.cpp:256]     Train net output #0: loss = 0.00472365 (* 1 = 0.00472365 loss)
I1205 21:15:25.889130  1846 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I1205 21:15:27.407167  1846 solver.cpp:349] Iteration 7500, Testing net (#0)
I1205 21:15:27.828205  1846 blocking_queue.cpp:50] Data layer prefetch queue empty
I1205 21:15:27.932828  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9903
I1205 21:15:27.932930  1846 solver.cpp:416]     Test net output #1: loss = 0.0327343 (* 1 = 0.0327343 loss)
I1205 21:15:27.937608  1846 solver.cpp:240] Iteration 7500, loss = 0.00227227
I1205 21:15:27.937696  1846 solver.cpp:256]     Train net output #0: loss = 0.00227218 (* 1 = 0.00227218 loss)
I1205 21:15:27.937757  1846 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I1205 21:15:29.510051  1846 solver.cpp:240] Iteration 7600, loss = 0.0097096
I1205 21:15:29.510216  1846 solver.cpp:256]     Train net output #0: loss = 0.00970951 (* 1 = 0.00970951 loss)
I1205 21:15:29.510314  1846 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I1205 21:15:31.056799  1846 solver.cpp:240] Iteration 7700, loss = 0.0282333
I1205 21:15:31.056951  1846 solver.cpp:256]     Train net output #0: loss = 0.0282332 (* 1 = 0.0282332 loss)
I1205 21:15:31.057035  1846 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I1205 21:15:32.615708  1846 solver.cpp:240] Iteration 7800, loss = 0.00462024
I1205 21:15:32.615880  1846 solver.cpp:256]     Train net output #0: loss = 0.00462014 (* 1 = 0.00462014 loss)
I1205 21:15:32.615978  1846 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I1205 21:15:34.179036  1846 solver.cpp:240] Iteration 7900, loss = 0.00254641
I1205 21:15:34.179191  1846 solver.cpp:256]     Train net output #0: loss = 0.00254632 (* 1 = 0.00254632 loss)
I1205 21:15:34.179306  1846 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I1205 21:15:35.707906  1846 solver.cpp:349] Iteration 8000, Testing net (#0)
I1205 21:15:36.287046  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9907
I1205 21:15:36.287468  1846 solver.cpp:416]     Test net output #1: loss = 0.030214 (* 1 = 0.030214 loss)
I1205 21:15:36.295020  1846 solver.cpp:240] Iteration 8000, loss = 0.00567453
I1205 21:15:36.295364  1846 solver.cpp:256]     Train net output #0: loss = 0.00567444 (* 1 = 0.00567444 loss)
I1205 21:15:36.295624  1846 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I1205 21:15:37.912966  1846 solver.cpp:240] Iteration 8100, loss = 0.0128112
I1205 21:15:37.913131  1846 solver.cpp:256]     Train net output #0: loss = 0.0128111 (* 1 = 0.0128111 loss)
I1205 21:15:37.913240  1846 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I1205 21:15:39.539093  1846 solver.cpp:240] Iteration 8200, loss = 0.00871631
I1205 21:15:39.539523  1846 solver.cpp:256]     Train net output #0: loss = 0.00871621 (* 1 = 0.00871621 loss)
I1205 21:15:39.539813  1846 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I1205 21:15:41.108320  1846 solver.cpp:240] Iteration 8300, loss = 0.0420773
I1205 21:15:41.108481  1846 solver.cpp:256]     Train net output #0: loss = 0.0420772 (* 1 = 0.0420772 loss)
I1205 21:15:41.108587  1846 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I1205 21:15:42.736552  1846 solver.cpp:240] Iteration 8400, loss = 0.00513953
I1205 21:15:42.737334  1846 solver.cpp:256]     Train net output #0: loss = 0.00513944 (* 1 = 0.00513944 loss)
I1205 21:15:42.737576  1846 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I1205 21:15:44.367938  1846 solver.cpp:349] Iteration 8500, Testing net (#0)
I1205 21:15:44.912185  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9895
I1205 21:15:44.912542  1846 solver.cpp:416]     Test net output #1: loss = 0.0308184 (* 1 = 0.0308184 loss)
I1205 21:15:44.918817  1846 solver.cpp:240] Iteration 8500, loss = 0.00553719
I1205 21:15:44.919126  1846 solver.cpp:256]     Train net output #0: loss = 0.00553709 (* 1 = 0.00553709 loss)
I1205 21:15:44.919363  1846 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I1205 21:15:46.485090  1846 solver.cpp:240] Iteration 8600, loss = 0.00164569
I1205 21:15:46.485242  1846 solver.cpp:256]     Train net output #0: loss = 0.00164559 (* 1 = 0.00164559 loss)
I1205 21:15:46.485324  1846 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I1205 21:15:48.017069  1846 solver.cpp:240] Iteration 8700, loss = 0.00442444
I1205 21:15:48.017264  1846 solver.cpp:256]     Train net output #0: loss = 0.00442434 (* 1 = 0.00442434 loss)
I1205 21:15:48.017351  1846 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I1205 21:15:49.539628  1846 solver.cpp:240] Iteration 8800, loss = 0.00133691
I1205 21:15:49.539790  1846 solver.cpp:256]     Train net output #0: loss = 0.00133681 (* 1 = 0.00133681 loss)
I1205 21:15:49.539906  1846 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I1205 21:15:51.065498  1846 solver.cpp:240] Iteration 8900, loss = 0.000605582
I1205 21:15:51.065668  1846 solver.cpp:256]     Train net output #0: loss = 0.000605487 (* 1 = 0.000605487 loss)
I1205 21:15:51.065788  1846 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I1205 21:15:52.579001  1846 solver.cpp:349] Iteration 9000, Testing net (#0)
I1205 21:15:53.120496  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9904
I1205 21:15:53.120857  1846 solver.cpp:416]     Test net output #1: loss = 0.0301244 (* 1 = 0.0301244 loss)
I1205 21:15:53.129566  1846 solver.cpp:240] Iteration 9000, loss = 0.0186689
I1205 21:15:53.129681  1846 solver.cpp:256]     Train net output #0: loss = 0.0186688 (* 1 = 0.0186688 loss)
I1205 21:15:53.129770  1846 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I1205 21:15:54.784533  1846 solver.cpp:240] Iteration 9100, loss = 0.00639552
I1205 21:15:54.784667  1846 solver.cpp:256]     Train net output #0: loss = 0.00639542 (* 1 = 0.00639542 loss)
I1205 21:15:54.784741  1846 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I1205 21:15:56.314811  1846 solver.cpp:240] Iteration 9200, loss = 0.00328946
I1205 21:15:56.314980  1846 solver.cpp:256]     Train net output #0: loss = 0.00328935 (* 1 = 0.00328935 loss)
I1205 21:15:56.315109  1846 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I1205 21:15:57.860206  1846 solver.cpp:240] Iteration 9300, loss = 0.00451656
I1205 21:15:57.860694  1846 solver.cpp:256]     Train net output #0: loss = 0.00451646 (* 1 = 0.00451646 loss)
I1205 21:15:57.861032  1846 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I1205 21:15:59.405789  1846 solver.cpp:240] Iteration 9400, loss = 0.0253838
I1205 21:15:59.405968  1846 solver.cpp:256]     Train net output #0: loss = 0.0253837 (* 1 = 0.0253837 loss)
I1205 21:15:59.406090  1846 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I1205 21:16:00.931921  1846 solver.cpp:349] Iteration 9500, Testing net (#0)
I1205 21:16:01.447793  1846 solver.cpp:416]     Test net output #0: accuracy = 0.99
I1205 21:16:01.447882  1846 solver.cpp:416]     Test net output #1: loss = 0.033485 (* 1 = 0.033485 loss)
I1205 21:16:01.452412  1846 solver.cpp:240] Iteration 9500, loss = 0.00331092
I1205 21:16:01.452488  1846 solver.cpp:256]     Train net output #0: loss = 0.00331081 (* 1 = 0.00331081 loss)
I1205 21:16:01.452534  1846 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I1205 21:16:02.990882  1846 solver.cpp:240] Iteration 9600, loss = 0.0030428
I1205 21:16:02.991055  1846 solver.cpp:256]     Train net output #0: loss = 0.00304269 (* 1 = 0.00304269 loss)
I1205 21:16:02.991158  1846 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I1205 21:16:04.532326  1846 solver.cpp:240] Iteration 9700, loss = 0.00247178
I1205 21:16:04.532500  1846 solver.cpp:256]     Train net output #0: loss = 0.00247167 (* 1 = 0.00247167 loss)
I1205 21:16:04.532599  1846 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I1205 21:16:06.149628  1846 solver.cpp:240] Iteration 9800, loss = 0.00894985
I1205 21:16:06.149771  1846 solver.cpp:256]     Train net output #0: loss = 0.00894975 (* 1 = 0.00894975 loss)
I1205 21:16:06.149859  1846 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I1205 21:16:07.721590  1846 solver.cpp:240] Iteration 9900, loss = 0.00437072
I1205 21:16:07.721756  1846 solver.cpp:256]     Train net output #0: loss = 0.00437062 (* 1 = 0.00437062 loss)
I1205 21:16:07.721869  1846 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I1205 21:16:09.363888  1846 solver.cpp:466] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I1205 21:16:09.420675  1846 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I1205 21:16:09.432209  1846 solver.cpp:349] Iteration 10000, Testing net (#0)
I1205 21:16:10.047485  1846 solver.cpp:416]     Test net output #0: accuracy = 0.991
I1205 21:16:10.047593  1846 solver.cpp:416]     Test net output #1: loss = 0.0292094 (* 1 = 0.0292094 loss)
I1205 21:16:10.053261  1846 solver.cpp:240] Iteration 10000, loss = 0.00202662
I1205 21:16:10.053357  1846 solver.cpp:256]     Train net output #0: loss = 0.00202653 (* 1 = 0.00202653 loss)
I1205 21:16:10.053462  1846 sgd_solver.cpp:106] Iteration 10000, lr = 0.00594604
I1205 21:16:11.624187  1846 solver.cpp:240] Iteration 10100, loss = 0.0127352
I1205 21:16:11.624354  1846 solver.cpp:256]     Train net output #0: loss = 0.0127351 (* 1 = 0.0127351 loss)
I1205 21:16:11.624595  1846 sgd_solver.cpp:106] Iteration 10100, lr = 0.00592384
I1205 21:16:13.179343  1846 solver.cpp:240] Iteration 10200, loss = 0.0127372
I1205 21:16:13.179507  1846 solver.cpp:256]     Train net output #0: loss = 0.0127371 (* 1 = 0.0127371 loss)
I1205 21:16:13.179625  1846 sgd_solver.cpp:106] Iteration 10200, lr = 0.00590183
I1205 21:16:14.724319  1846 solver.cpp:240] Iteration 10300, loss = 0.000256046
I1205 21:16:14.724476  1846 solver.cpp:256]     Train net output #0: loss = 0.000255953 (* 1 = 0.000255953 loss)
I1205 21:16:14.724572  1846 sgd_solver.cpp:106] Iteration 10300, lr = 0.00588001
I1205 21:16:16.270861  1846 solver.cpp:240] Iteration 10400, loss = 0.00379216
I1205 21:16:16.271039  1846 solver.cpp:256]     Train net output #0: loss = 0.00379206 (* 1 = 0.00379206 loss)
I1205 21:16:16.271137  1846 sgd_solver.cpp:106] Iteration 10400, lr = 0.00585838
I1205 21:16:17.817900  1846 solver.cpp:349] Iteration 10500, Testing net (#0)
I1205 21:16:18.345679  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9903
I1205 21:16:18.345777  1846 solver.cpp:416]     Test net output #1: loss = 0.0323232 (* 1 = 0.0323232 loss)
I1205 21:16:18.350764  1846 solver.cpp:240] Iteration 10500, loss = 0.00904525
I1205 21:16:18.350854  1846 solver.cpp:256]     Train net output #0: loss = 0.00904515 (* 1 = 0.00904515 loss)
I1205 21:16:18.350909  1846 sgd_solver.cpp:106] Iteration 10500, lr = 0.00583693
I1205 21:16:19.894829  1846 solver.cpp:240] Iteration 10600, loss = 0.00497998
I1205 21:16:19.895000  1846 solver.cpp:256]     Train net output #0: loss = 0.00497988 (* 1 = 0.00497988 loss)
I1205 21:16:19.895109  1846 sgd_solver.cpp:106] Iteration 10600, lr = 0.00581567
I1205 21:16:21.429937  1846 solver.cpp:240] Iteration 10700, loss = 0.00679337
I1205 21:16:21.430101  1846 solver.cpp:256]     Train net output #0: loss = 0.00679327 (* 1 = 0.00679327 loss)
I1205 21:16:21.430208  1846 sgd_solver.cpp:106] Iteration 10700, lr = 0.00579458
I1205 21:16:22.966799  1846 solver.cpp:240] Iteration 10800, loss = 0.00265065
I1205 21:16:22.967581  1846 solver.cpp:256]     Train net output #0: loss = 0.00265055 (* 1 = 0.00265055 loss)
I1205 21:16:22.967694  1846 sgd_solver.cpp:106] Iteration 10800, lr = 0.00577368
I1205 21:16:24.511138  1846 solver.cpp:240] Iteration 10900, loss = 0.00175621
I1205 21:16:24.511329  1846 solver.cpp:256]     Train net output #0: loss = 0.00175612 (* 1 = 0.00175612 loss)
I1205 21:16:24.511456  1846 sgd_solver.cpp:106] Iteration 10900, lr = 0.00575295
I1205 21:16:26.017843  1846 solver.cpp:349] Iteration 11000, Testing net (#0)
I1205 21:16:26.556665  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9892
I1205 21:16:26.557025  1846 solver.cpp:416]     Test net output #1: loss = 0.0342961 (* 1 = 0.0342961 loss)
I1205 21:16:26.562408  1846 solver.cpp:240] Iteration 11000, loss = 0.00144964
I1205 21:16:26.562716  1846 solver.cpp:256]     Train net output #0: loss = 0.00144954 (* 1 = 0.00144954 loss)
I1205 21:16:26.562947  1846 sgd_solver.cpp:106] Iteration 11000, lr = 0.00573239
I1205 21:16:28.158417  1846 solver.cpp:240] Iteration 11100, loss = 0.00906242
I1205 21:16:28.158551  1846 solver.cpp:256]     Train net output #0: loss = 0.00906233 (* 1 = 0.00906233 loss)
I1205 21:16:28.158639  1846 sgd_solver.cpp:106] Iteration 11100, lr = 0.005712
I1205 21:16:29.809984  1846 solver.cpp:240] Iteration 11200, loss = 0.00875615
I1205 21:16:29.810117  1846 solver.cpp:256]     Train net output #0: loss = 0.00875606 (* 1 = 0.00875606 loss)
I1205 21:16:29.810196  1846 sgd_solver.cpp:106] Iteration 11200, lr = 0.00569178
I1205 21:16:31.464705  1846 solver.cpp:240] Iteration 11300, loss = 0.00486503
I1205 21:16:31.464866  1846 solver.cpp:256]     Train net output #0: loss = 0.00486493 (* 1 = 0.00486493 loss)
I1205 21:16:31.465006  1846 sgd_solver.cpp:106] Iteration 11300, lr = 0.00567173
I1205 21:16:33.100292  1846 solver.cpp:240] Iteration 11400, loss = 0.00479566
I1205 21:16:33.100695  1846 solver.cpp:256]     Train net output #0: loss = 0.00479555 (* 1 = 0.00479555 loss)
I1205 21:16:33.100952  1846 sgd_solver.cpp:106] Iteration 11400, lr = 0.00565184
I1205 21:16:34.614534  1846 solver.cpp:349] Iteration 11500, Testing net (#0)
I1205 21:16:35.187081  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9902
I1205 21:16:35.187206  1846 solver.cpp:416]     Test net output #1: loss = 0.0310708 (* 1 = 0.0310708 loss)
I1205 21:16:35.192517  1846 solver.cpp:240] Iteration 11500, loss = 0.00539531
I1205 21:16:35.192598  1846 solver.cpp:256]     Train net output #0: loss = 0.0053952 (* 1 = 0.0053952 loss)
I1205 21:16:35.192644  1846 sgd_solver.cpp:106] Iteration 11500, lr = 0.00563211
I1205 21:16:36.818513  1846 solver.cpp:240] Iteration 11600, loss = 0.00302207
I1205 21:16:36.818663  1846 solver.cpp:256]     Train net output #0: loss = 0.00302196 (* 1 = 0.00302196 loss)
I1205 21:16:36.818758  1846 sgd_solver.cpp:106] Iteration 11600, lr = 0.00561254
I1205 21:16:38.393847  1846 solver.cpp:240] Iteration 11700, loss = 0.00284028
I1205 21:16:38.393997  1846 solver.cpp:256]     Train net output #0: loss = 0.00284017 (* 1 = 0.00284017 loss)
I1205 21:16:38.394081  1846 sgd_solver.cpp:106] Iteration 11700, lr = 0.00559313
I1205 21:16:39.969909  1846 solver.cpp:240] Iteration 11800, loss = 0.00952012
I1205 21:16:39.970057  1846 solver.cpp:256]     Train net output #0: loss = 0.00952002 (* 1 = 0.00952002 loss)
I1205 21:16:39.970140  1846 sgd_solver.cpp:106] Iteration 11800, lr = 0.00557388
I1205 21:16:41.538377  1846 solver.cpp:240] Iteration 11900, loss = 0.006407
I1205 21:16:41.538532  1846 solver.cpp:256]     Train net output #0: loss = 0.00640689 (* 1 = 0.00640689 loss)
I1205 21:16:41.538617  1846 sgd_solver.cpp:106] Iteration 11900, lr = 0.00555478
I1205 21:16:43.100324  1846 solver.cpp:349] Iteration 12000, Testing net (#0)
I1205 21:16:43.630022  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9906
I1205 21:16:43.630111  1846 solver.cpp:416]     Test net output #1: loss = 0.0317062 (* 1 = 0.0317062 loss)
I1205 21:16:43.636163  1846 solver.cpp:240] Iteration 12000, loss = 0.00346464
I1205 21:16:43.636243  1846 solver.cpp:256]     Train net output #0: loss = 0.00346454 (* 1 = 0.00346454 loss)
I1205 21:16:43.636507  1846 sgd_solver.cpp:106] Iteration 12000, lr = 0.00553583
I1205 21:16:45.294617  1846 solver.cpp:240] Iteration 12100, loss = 0.00600097
I1205 21:16:45.294764  1846 solver.cpp:256]     Train net output #0: loss = 0.00600086 (* 1 = 0.00600086 loss)
I1205 21:16:45.294849  1846 sgd_solver.cpp:106] Iteration 12100, lr = 0.00551704
I1205 21:16:46.950094  1846 solver.cpp:240] Iteration 12200, loss = 0.00216881
I1205 21:16:46.950222  1846 solver.cpp:256]     Train net output #0: loss = 0.00216871 (* 1 = 0.00216871 loss)
I1205 21:16:46.950297  1846 sgd_solver.cpp:106] Iteration 12200, lr = 0.00549839
I1205 21:16:48.523241  1846 solver.cpp:240] Iteration 12300, loss = 0.00445013
I1205 21:16:48.523440  1846 solver.cpp:256]     Train net output #0: loss = 0.00445003 (* 1 = 0.00445003 loss)
I1205 21:16:48.523548  1846 sgd_solver.cpp:106] Iteration 12300, lr = 0.00547988
I1205 21:16:50.175308  1846 solver.cpp:240] Iteration 12400, loss = 0.00118431
I1205 21:16:50.175438  1846 solver.cpp:256]     Train net output #0: loss = 0.0011842 (* 1 = 0.0011842 loss)
I1205 21:16:50.175511  1846 sgd_solver.cpp:106] Iteration 12400, lr = 0.00546153
I1205 21:16:51.809171  1846 solver.cpp:349] Iteration 12500, Testing net (#0)
I1205 21:16:52.410368  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9907
I1205 21:16:52.410454  1846 solver.cpp:416]     Test net output #1: loss = 0.0292432 (* 1 = 0.0292432 loss)
I1205 21:16:52.415907  1846 solver.cpp:240] Iteration 12500, loss = 0.00936843
I1205 21:16:52.415989  1846 solver.cpp:256]     Train net output #0: loss = 0.00936832 (* 1 = 0.00936832 loss)
I1205 21:16:52.416036  1846 sgd_solver.cpp:106] Iteration 12500, lr = 0.00544331
I1205 21:16:54.005429  1846 solver.cpp:240] Iteration 12600, loss = 0.0147122
I1205 21:16:54.005825  1846 solver.cpp:256]     Train net output #0: loss = 0.0147121 (* 1 = 0.0147121 loss)
I1205 21:16:54.005913  1846 sgd_solver.cpp:106] Iteration 12600, lr = 0.00542524
I1205 21:16:55.571972  1846 solver.cpp:240] Iteration 12700, loss = 0.00580716
I1205 21:16:55.572119  1846 solver.cpp:256]     Train net output #0: loss = 0.00580705 (* 1 = 0.00580705 loss)
I1205 21:16:55.572206  1846 sgd_solver.cpp:106] Iteration 12700, lr = 0.0054073
I1205 21:16:57.137603  1846 solver.cpp:240] Iteration 12800, loss = 0.00137981
I1205 21:16:57.137751  1846 solver.cpp:256]     Train net output #0: loss = 0.00137971 (* 1 = 0.00137971 loss)
I1205 21:16:57.137840  1846 sgd_solver.cpp:106] Iteration 12800, lr = 0.0053895
I1205 21:16:58.724901  1846 solver.cpp:240] Iteration 12900, loss = 0.00404761
I1205 21:16:58.725061  1846 solver.cpp:256]     Train net output #0: loss = 0.00404751 (* 1 = 0.00404751 loss)
I1205 21:16:58.725170  1846 sgd_solver.cpp:106] Iteration 12900, lr = 0.00537184
I1205 21:17:00.308647  1846 solver.cpp:349] Iteration 13000, Testing net (#0)
I1205 21:17:00.822620  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9904
I1205 21:17:00.822711  1846 solver.cpp:416]     Test net output #1: loss = 0.0323728 (* 1 = 0.0323728 loss)
I1205 21:17:00.828416  1846 solver.cpp:240] Iteration 13000, loss = 0.00208939
I1205 21:17:00.828500  1846 solver.cpp:256]     Train net output #0: loss = 0.00208929 (* 1 = 0.00208929 loss)
I1205 21:17:00.828548  1846 sgd_solver.cpp:106] Iteration 13000, lr = 0.00535432
I1205 21:17:02.452150  1846 solver.cpp:240] Iteration 13100, loss = 0.000254121
I1205 21:17:02.452510  1846 solver.cpp:256]     Train net output #0: loss = 0.000254027 (* 1 = 0.000254027 loss)
I1205 21:17:02.452735  1846 sgd_solver.cpp:106] Iteration 13100, lr = 0.00533692
I1205 21:17:04.069046  1846 solver.cpp:240] Iteration 13200, loss = 0.00202909
I1205 21:17:04.069213  1846 solver.cpp:256]     Train net output #0: loss = 0.00202899 (* 1 = 0.00202899 loss)
I1205 21:17:04.069311  1846 sgd_solver.cpp:106] Iteration 13200, lr = 0.00531966
I1205 21:17:05.597970  1846 solver.cpp:240] Iteration 13300, loss = 0.00695951
I1205 21:17:05.598140  1846 solver.cpp:256]     Train net output #0: loss = 0.00695942 (* 1 = 0.00695942 loss)
I1205 21:17:05.598237  1846 sgd_solver.cpp:106] Iteration 13300, lr = 0.00530253
I1205 21:17:07.126003  1846 solver.cpp:240] Iteration 13400, loss = 0.00392755
I1205 21:17:07.126150  1846 solver.cpp:256]     Train net output #0: loss = 0.00392746 (* 1 = 0.00392746 loss)
I1205 21:17:07.126235  1846 sgd_solver.cpp:106] Iteration 13400, lr = 0.00528552
I1205 21:17:08.641731  1846 solver.cpp:349] Iteration 13500, Testing net (#0)
I1205 21:17:09.334816  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9907
I1205 21:17:09.334936  1846 solver.cpp:416]     Test net output #1: loss = 0.0295715 (* 1 = 0.0295715 loss)
I1205 21:17:09.343112  1846 solver.cpp:240] Iteration 13500, loss = 0.00359821
I1205 21:17:09.343224  1846 solver.cpp:256]     Train net output #0: loss = 0.00359811 (* 1 = 0.00359811 loss)
I1205 21:17:09.343299  1846 sgd_solver.cpp:106] Iteration 13500, lr = 0.00526865
I1205 21:17:10.942771  1846 solver.cpp:240] Iteration 13600, loss = 0.00086789
I1205 21:17:10.942939  1846 solver.cpp:256]     Train net output #0: loss = 0.000867789 (* 1 = 0.000867789 loss)
I1205 21:17:10.943053  1846 sgd_solver.cpp:106] Iteration 13600, lr = 0.00525189
I1205 21:17:12.490878  1846 solver.cpp:240] Iteration 13700, loss = 0.00228031
I1205 21:17:12.491021  1846 solver.cpp:256]     Train net output #0: loss = 0.00228021 (* 1 = 0.00228021 loss)
I1205 21:17:12.491111  1846 sgd_solver.cpp:106] Iteration 13700, lr = 0.00523527
I1205 21:17:14.019723  1846 solver.cpp:240] Iteration 13800, loss = 0.00264828
I1205 21:17:14.019891  1846 solver.cpp:256]     Train net output #0: loss = 0.00264818 (* 1 = 0.00264818 loss)
I1205 21:17:14.020011  1846 sgd_solver.cpp:106] Iteration 13800, lr = 0.00521876
I1205 21:17:15.548733  1846 solver.cpp:240] Iteration 13900, loss = 0.00318942
I1205 21:17:15.548899  1846 solver.cpp:256]     Train net output #0: loss = 0.00318932 (* 1 = 0.00318932 loss)
I1205 21:17:15.549147  1846 sgd_solver.cpp:106] Iteration 13900, lr = 0.00520237
I1205 21:17:17.061683  1846 solver.cpp:349] Iteration 14000, Testing net (#0)
I1205 21:17:17.637686  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9906
I1205 21:17:17.637998  1846 solver.cpp:416]     Test net output #1: loss = 0.0291196 (* 1 = 0.0291196 loss)
I1205 21:17:17.643653  1846 solver.cpp:240] Iteration 14000, loss = 0.00339418
I1205 21:17:17.643923  1846 solver.cpp:256]     Train net output #0: loss = 0.00339408 (* 1 = 0.00339408 loss)
I1205 21:17:17.644111  1846 sgd_solver.cpp:106] Iteration 14000, lr = 0.00518611
I1205 21:17:19.215656  1846 solver.cpp:240] Iteration 14100, loss = 0.0120033
I1205 21:17:19.215816  1846 solver.cpp:256]     Train net output #0: loss = 0.0120032 (* 1 = 0.0120032 loss)
I1205 21:17:19.215931  1846 sgd_solver.cpp:106] Iteration 14100, lr = 0.00516996
I1205 21:17:20.792848  1846 solver.cpp:240] Iteration 14200, loss = 0.00617024
I1205 21:17:20.792990  1846 solver.cpp:256]     Train net output #0: loss = 0.00617015 (* 1 = 0.00617015 loss)
I1205 21:17:20.793088  1846 sgd_solver.cpp:106] Iteration 14200, lr = 0.00515393
I1205 21:17:22.371132  1846 solver.cpp:240] Iteration 14300, loss = 0.00236598
I1205 21:17:22.371279  1846 solver.cpp:256]     Train net output #0: loss = 0.00236588 (* 1 = 0.00236588 loss)
I1205 21:17:22.371374  1846 sgd_solver.cpp:106] Iteration 14300, lr = 0.00513801
I1205 21:17:23.964279  1846 solver.cpp:240] Iteration 14400, loss = 0.00242
I1205 21:17:23.964411  1846 solver.cpp:256]     Train net output #0: loss = 0.00241991 (* 1 = 0.00241991 loss)
I1205 21:17:23.964500  1846 sgd_solver.cpp:106] Iteration 14400, lr = 0.00512221
I1205 21:17:25.493206  1846 solver.cpp:349] Iteration 14500, Testing net (#0)
I1205 21:17:26.296684  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9905
I1205 21:17:26.296797  1846 solver.cpp:416]     Test net output #1: loss = 0.0296619 (* 1 = 0.0296619 loss)
I1205 21:17:26.304992  1846 solver.cpp:240] Iteration 14500, loss = 0.00198162
I1205 21:17:26.305104  1846 solver.cpp:256]     Train net output #0: loss = 0.00198152 (* 1 = 0.00198152 loss)
I1205 21:17:26.305184  1846 sgd_solver.cpp:106] Iteration 14500, lr = 0.00510652
I1205 21:17:27.984567  1846 solver.cpp:240] Iteration 14600, loss = 0.00630955
I1205 21:17:27.984721  1846 solver.cpp:256]     Train net output #0: loss = 0.00630945 (* 1 = 0.00630945 loss)
I1205 21:17:27.984807  1846 sgd_solver.cpp:106] Iteration 14600, lr = 0.00509095
I1205 21:17:29.565343  1846 solver.cpp:240] Iteration 14700, loss = 0.00233874
I1205 21:17:29.565491  1846 solver.cpp:256]     Train net output #0: loss = 0.00233864 (* 1 = 0.00233864 loss)
I1205 21:17:29.565580  1846 sgd_solver.cpp:106] Iteration 14700, lr = 0.00507548
I1205 21:17:31.137823  1846 solver.cpp:240] Iteration 14800, loss = 0.00977252
I1205 21:17:31.137980  1846 solver.cpp:256]     Train net output #0: loss = 0.00977242 (* 1 = 0.00977242 loss)
I1205 21:17:31.138077  1846 sgd_solver.cpp:106] Iteration 14800, lr = 0.00506012
I1205 21:17:32.687163  1846 solver.cpp:240] Iteration 14900, loss = 0.00373717
I1205 21:17:32.687358  1846 solver.cpp:256]     Train net output #0: loss = 0.00373707 (* 1 = 0.00373707 loss)
I1205 21:17:32.687468  1846 sgd_solver.cpp:106] Iteration 14900, lr = 0.00504488
I1205 21:17:34.226418  1846 solver.cpp:466] Snapshotting to binary proto file examples/mnist/lenet_iter_15000.caffemodel
I1205 21:17:34.283807  1846 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_15000.solverstate
I1205 21:17:34.295842  1846 solver.cpp:349] Iteration 15000, Testing net (#0)
I1205 21:17:34.973986  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9903
I1205 21:17:34.974072  1846 solver.cpp:416]     Test net output #1: loss = 0.0310817 (* 1 = 0.0310817 loss)
I1205 21:17:34.979842  1846 solver.cpp:240] Iteration 15000, loss = 0.00294706
I1205 21:17:34.979933  1846 solver.cpp:256]     Train net output #0: loss = 0.00294696 (* 1 = 0.00294696 loss)
I1205 21:17:34.979995  1846 sgd_solver.cpp:106] Iteration 15000, lr = 0.00502973
I1205 21:17:36.540071  1846 solver.cpp:240] Iteration 15100, loss = 0.00391837
I1205 21:17:36.540231  1846 solver.cpp:256]     Train net output #0: loss = 0.00391827 (* 1 = 0.00391827 loss)
I1205 21:17:36.540323  1846 sgd_solver.cpp:106] Iteration 15100, lr = 0.0050147
I1205 21:17:38.176137  1846 solver.cpp:240] Iteration 15200, loss = 0.00760851
I1205 21:17:38.176596  1846 solver.cpp:256]     Train net output #0: loss = 0.0076084 (* 1 = 0.0076084 loss)
I1205 21:17:38.176890  1846 sgd_solver.cpp:106] Iteration 15200, lr = 0.00499976
I1205 21:17:39.720790  1846 solver.cpp:240] Iteration 15300, loss = 0.00226349
I1205 21:17:39.720929  1846 solver.cpp:256]     Train net output #0: loss = 0.00226339 (* 1 = 0.00226339 loss)
I1205 21:17:39.721021  1846 sgd_solver.cpp:106] Iteration 15300, lr = 0.00498494
I1205 21:17:41.294193  1846 solver.cpp:240] Iteration 15400, loss = 0.00127862
I1205 21:17:41.294360  1846 solver.cpp:256]     Train net output #0: loss = 0.00127852 (* 1 = 0.00127852 loss)
I1205 21:17:41.294479  1846 sgd_solver.cpp:106] Iteration 15400, lr = 0.00497021
I1205 21:17:42.862329  1846 solver.cpp:349] Iteration 15500, Testing net (#0)
I1205 21:17:43.399511  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9907
I1205 21:17:43.399600  1846 solver.cpp:416]     Test net output #1: loss = 0.0298204 (* 1 = 0.0298204 loss)
I1205 21:17:43.404145  1846 solver.cpp:240] Iteration 15500, loss = 0.00348046
I1205 21:17:43.404223  1846 solver.cpp:256]     Train net output #0: loss = 0.00348036 (* 1 = 0.00348036 loss)
I1205 21:17:43.404274  1846 sgd_solver.cpp:106] Iteration 15500, lr = 0.00495558
I1205 21:17:44.938388  1846 solver.cpp:240] Iteration 15600, loss = 0.00469873
I1205 21:17:44.938552  1846 solver.cpp:256]     Train net output #0: loss = 0.00469863 (* 1 = 0.00469863 loss)
I1205 21:17:44.938805  1846 sgd_solver.cpp:106] Iteration 15600, lr = 0.00494106
I1205 21:17:46.577286  1846 solver.cpp:240] Iteration 15700, loss = 0.00532667
I1205 21:17:46.577729  1846 solver.cpp:256]     Train net output #0: loss = 0.00532658 (* 1 = 0.00532658 loss)
I1205 21:17:46.578038  1846 sgd_solver.cpp:106] Iteration 15700, lr = 0.00492663
I1205 21:17:48.229393  1846 solver.cpp:240] Iteration 15800, loss = 0.0175586
I1205 21:17:48.229543  1846 solver.cpp:256]     Train net output #0: loss = 0.0175586 (* 1 = 0.0175586 loss)
I1205 21:17:48.229640  1846 sgd_solver.cpp:106] Iteration 15800, lr = 0.0049123
I1205 21:17:49.798223  1846 solver.cpp:240] Iteration 15900, loss = 0.00403605
I1205 21:17:49.798369  1846 solver.cpp:256]     Train net output #0: loss = 0.00403595 (* 1 = 0.00403595 loss)
I1205 21:17:49.798463  1846 sgd_solver.cpp:106] Iteration 15900, lr = 0.00489807
I1205 21:17:51.353993  1846 solver.cpp:349] Iteration 16000, Testing net (#0)
I1205 21:17:51.883852  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9905
I1205 21:17:51.883946  1846 solver.cpp:416]     Test net output #1: loss = 0.0290855 (* 1 = 0.0290855 loss)
I1205 21:17:51.888907  1846 solver.cpp:240] Iteration 16000, loss = 0.00367783
I1205 21:17:51.888988  1846 solver.cpp:256]     Train net output #0: loss = 0.00367773 (* 1 = 0.00367773 loss)
I1205 21:17:51.889039  1846 sgd_solver.cpp:106] Iteration 16000, lr = 0.00488394
I1205 21:17:53.430229  1846 solver.cpp:240] Iteration 16100, loss = 0.00111509
I1205 21:17:53.430402  1846 solver.cpp:256]     Train net output #0: loss = 0.00111499 (* 1 = 0.00111499 loss)
I1205 21:17:53.430505  1846 sgd_solver.cpp:106] Iteration 16100, lr = 0.0048699
I1205 21:17:54.972090  1846 solver.cpp:240] Iteration 16200, loss = 0.00199003
I1205 21:17:54.972285  1846 solver.cpp:256]     Train net output #0: loss = 0.00198993 (* 1 = 0.00198993 loss)
I1205 21:17:54.972409  1846 sgd_solver.cpp:106] Iteration 16200, lr = 0.00485595
I1205 21:17:56.495839  1846 solver.cpp:240] Iteration 16300, loss = 0.000883438
I1205 21:17:56.496450  1846 solver.cpp:256]     Train net output #0: loss = 0.00088334 (* 1 = 0.00088334 loss)
I1205 21:17:56.496549  1846 sgd_solver.cpp:106] Iteration 16300, lr = 0.00484209
I1205 21:17:58.028213  1846 solver.cpp:240] Iteration 16400, loss = 0.000949127
I1205 21:17:58.028374  1846 solver.cpp:256]     Train net output #0: loss = 0.000949026 (* 1 = 0.000949026 loss)
I1205 21:17:58.028492  1846 sgd_solver.cpp:106] Iteration 16400, lr = 0.00482833
I1205 21:17:59.554011  1846 solver.cpp:349] Iteration 16500, Testing net (#0)
I1205 21:18:00.088708  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9905
I1205 21:18:00.088805  1846 solver.cpp:416]     Test net output #1: loss = 0.0280804 (* 1 = 0.0280804 loss)
I1205 21:18:00.095057  1846 solver.cpp:240] Iteration 16500, loss = 0.0091542
I1205 21:18:00.095154  1846 solver.cpp:256]     Train net output #0: loss = 0.00915409 (* 1 = 0.00915409 loss)
I1205 21:18:00.095211  1846 sgd_solver.cpp:106] Iteration 16500, lr = 0.00481466
I1205 21:18:01.665344  1846 solver.cpp:240] Iteration 16600, loss = 0.00490443
I1205 21:18:01.665494  1846 solver.cpp:256]     Train net output #0: loss = 0.00490433 (* 1 = 0.00490433 loss)
I1205 21:18:01.665581  1846 sgd_solver.cpp:106] Iteration 16600, lr = 0.00480108
I1205 21:18:03.201731  1846 solver.cpp:240] Iteration 16700, loss = 0.00299697
I1205 21:18:03.201900  1846 solver.cpp:256]     Train net output #0: loss = 0.00299687 (* 1 = 0.00299687 loss)
I1205 21:18:03.202003  1846 sgd_solver.cpp:106] Iteration 16700, lr = 0.00478759
I1205 21:18:04.750145  1846 solver.cpp:240] Iteration 16800, loss = 0.00336122
I1205 21:18:04.750296  1846 solver.cpp:256]     Train net output #0: loss = 0.00336112 (* 1 = 0.00336112 loss)
I1205 21:18:04.750383  1846 sgd_solver.cpp:106] Iteration 16800, lr = 0.00477418
I1205 21:18:06.293337  1846 solver.cpp:240] Iteration 16900, loss = 0.00578565
I1205 21:18:06.293509  1846 solver.cpp:256]     Train net output #0: loss = 0.00578555 (* 1 = 0.00578555 loss)
I1205 21:18:06.293609  1846 sgd_solver.cpp:106] Iteration 16900, lr = 0.00476086
I1205 21:18:07.812432  1846 solver.cpp:349] Iteration 17000, Testing net (#0)
I1205 21:18:08.414268  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9902
I1205 21:18:08.414504  1846 solver.cpp:416]     Test net output #1: loss = 0.0304228 (* 1 = 0.0304228 loss)
I1205 21:18:08.419669  1846 solver.cpp:240] Iteration 17000, loss = 0.00222176
I1205 21:18:08.419901  1846 solver.cpp:256]     Train net output #0: loss = 0.00222165 (* 1 = 0.00222165 loss)
I1205 21:18:08.420033  1846 sgd_solver.cpp:106] Iteration 17000, lr = 0.00474763
I1205 21:18:09.994523  1846 solver.cpp:240] Iteration 17100, loss = 0.00200895
I1205 21:18:09.994693  1846 solver.cpp:256]     Train net output #0: loss = 0.00200884 (* 1 = 0.00200884 loss)
I1205 21:18:09.994822  1846 sgd_solver.cpp:106] Iteration 17100, lr = 0.00473449
I1205 21:18:11.520706  1846 solver.cpp:240] Iteration 17200, loss = 0.00140794
I1205 21:18:11.520876  1846 solver.cpp:256]     Train net output #0: loss = 0.00140784 (* 1 = 0.00140784 loss)
I1205 21:18:11.520977  1846 sgd_solver.cpp:106] Iteration 17200, lr = 0.00472143
I1205 21:18:13.065220  1846 solver.cpp:240] Iteration 17300, loss = 0.00542925
I1205 21:18:13.065368  1846 solver.cpp:256]     Train net output #0: loss = 0.00542914 (* 1 = 0.00542914 loss)
I1205 21:18:13.065455  1846 sgd_solver.cpp:106] Iteration 17300, lr = 0.00470845
I1205 21:18:14.611119  1846 solver.cpp:240] Iteration 17400, loss = 0.00328342
I1205 21:18:14.611284  1846 solver.cpp:256]     Train net output #0: loss = 0.00328331 (* 1 = 0.00328331 loss)
I1205 21:18:14.611394  1846 sgd_solver.cpp:106] Iteration 17400, lr = 0.00469556
I1205 21:18:16.126801  1846 solver.cpp:349] Iteration 17500, Testing net (#0)
I1205 21:18:16.675817  1846 solver.cpp:416]     Test net output #0: accuracy = 0.991
I1205 21:18:16.675950  1846 solver.cpp:416]     Test net output #1: loss = 0.0274537 (* 1 = 0.0274537 loss)
I1205 21:18:16.682955  1846 solver.cpp:240] Iteration 17500, loss = 0.00137784
I1205 21:18:16.683074  1846 solver.cpp:256]     Train net output #0: loss = 0.00137773 (* 1 = 0.00137773 loss)
I1205 21:18:16.683259  1846 sgd_solver.cpp:106] Iteration 17500, lr = 0.00468274
I1205 21:18:18.280733  1846 solver.cpp:240] Iteration 17600, loss = 0.00906543
I1205 21:18:18.280877  1846 solver.cpp:256]     Train net output #0: loss = 0.00906532 (* 1 = 0.00906532 loss)
I1205 21:18:18.280973  1846 sgd_solver.cpp:106] Iteration 17600, lr = 0.00467001
I1205 21:18:19.815644  1846 solver.cpp:240] Iteration 17700, loss = 0.00902383
I1205 21:18:19.815786  1846 solver.cpp:256]     Train net output #0: loss = 0.00902372 (* 1 = 0.00902372 loss)
I1205 21:18:19.815882  1846 sgd_solver.cpp:106] Iteration 17700, lr = 0.00465736
I1205 21:18:21.349480  1846 solver.cpp:240] Iteration 17800, loss = 0.000162503
I1205 21:18:21.349656  1846 solver.cpp:256]     Train net output #0: loss = 0.000162389 (* 1 = 0.000162389 loss)
I1205 21:18:21.349767  1846 sgd_solver.cpp:106] Iteration 17800, lr = 0.00464479
I1205 21:18:22.881131  1846 solver.cpp:240] Iteration 17900, loss = 0.00373359
I1205 21:18:22.881278  1846 solver.cpp:256]     Train net output #0: loss = 0.00373347 (* 1 = 0.00373347 loss)
I1205 21:18:22.881366  1846 sgd_solver.cpp:106] Iteration 17900, lr = 0.0046323
I1205 21:18:24.400951  1846 solver.cpp:349] Iteration 18000, Testing net (#0)
I1205 21:18:24.981900  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9901
I1205 21:18:24.982233  1846 solver.cpp:416]     Test net output #1: loss = 0.0303733 (* 1 = 0.0303733 loss)
I1205 21:18:24.988075  1846 solver.cpp:240] Iteration 18000, loss = 0.00516824
I1205 21:18:24.988363  1846 solver.cpp:256]     Train net output #0: loss = 0.00516812 (* 1 = 0.00516812 loss)
I1205 21:18:24.988579  1846 sgd_solver.cpp:106] Iteration 18000, lr = 0.00461989
I1205 21:18:26.517913  1846 solver.cpp:240] Iteration 18100, loss = 0.00383543
I1205 21:18:26.518580  1846 solver.cpp:256]     Train net output #0: loss = 0.00383532 (* 1 = 0.00383532 loss)
I1205 21:18:26.518676  1846 sgd_solver.cpp:106] Iteration 18100, lr = 0.00460755
I1205 21:18:28.059303  1846 solver.cpp:240] Iteration 18200, loss = 0.00383696
I1205 21:18:28.059471  1846 solver.cpp:256]     Train net output #0: loss = 0.00383685 (* 1 = 0.00383685 loss)
I1205 21:18:28.059594  1846 sgd_solver.cpp:106] Iteration 18200, lr = 0.00459529
I1205 21:18:29.589915  1846 solver.cpp:240] Iteration 18300, loss = 0.00171361
I1205 21:18:29.590075  1846 solver.cpp:256]     Train net output #0: loss = 0.0017135 (* 1 = 0.0017135 loss)
I1205 21:18:29.590160  1846 sgd_solver.cpp:106] Iteration 18300, lr = 0.00458311
I1205 21:18:31.122179  1846 solver.cpp:240] Iteration 18400, loss = 0.00131242
I1205 21:18:31.122380  1846 solver.cpp:256]     Train net output #0: loss = 0.00131231 (* 1 = 0.00131231 loss)
I1205 21:18:31.122493  1846 sgd_solver.cpp:106] Iteration 18400, lr = 0.004571
I1205 21:18:32.695843  1846 solver.cpp:349] Iteration 18500, Testing net (#0)
I1205 21:18:33.230686  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9898
I1205 21:18:33.230819  1846 solver.cpp:416]     Test net output #1: loss = 0.0305852 (* 1 = 0.0305852 loss)
I1205 21:18:33.235987  1846 solver.cpp:240] Iteration 18500, loss = 0.00111892
I1205 21:18:33.236104  1846 solver.cpp:256]     Train net output #0: loss = 0.00111881 (* 1 = 0.00111881 loss)
I1205 21:18:33.236181  1846 sgd_solver.cpp:106] Iteration 18500, lr = 0.00455897
I1205 21:18:34.809347  1846 solver.cpp:240] Iteration 18600, loss = 0.00794248
I1205 21:18:34.809497  1846 solver.cpp:256]     Train net output #0: loss = 0.00794237 (* 1 = 0.00794237 loss)
I1205 21:18:34.809593  1846 sgd_solver.cpp:106] Iteration 18600, lr = 0.00454701
I1205 21:18:36.378681  1846 solver.cpp:240] Iteration 18700, loss = 0.00573561
I1205 21:18:36.378821  1846 solver.cpp:256]     Train net output #0: loss = 0.0057355 (* 1 = 0.0057355 loss)
I1205 21:18:36.378907  1846 sgd_solver.cpp:106] Iteration 18700, lr = 0.00453512
I1205 21:18:37.949399  1846 solver.cpp:240] Iteration 18800, loss = 0.00488622
I1205 21:18:37.949548  1846 solver.cpp:256]     Train net output #0: loss = 0.00488611 (* 1 = 0.00488611 loss)
I1205 21:18:37.949640  1846 sgd_solver.cpp:106] Iteration 18800, lr = 0.0045233
I1205 21:18:39.517638  1846 solver.cpp:240] Iteration 18900, loss = 0.00419502
I1205 21:18:39.517777  1846 solver.cpp:256]     Train net output #0: loss = 0.00419491 (* 1 = 0.00419491 loss)
I1205 21:18:39.517874  1846 sgd_solver.cpp:106] Iteration 18900, lr = 0.00451156
I1205 21:18:41.073074  1846 solver.cpp:349] Iteration 19000, Testing net (#0)
I1205 21:18:41.607148  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9904
I1205 21:18:41.607239  1846 solver.cpp:416]     Test net output #1: loss = 0.0295134 (* 1 = 0.0295134 loss)
I1205 21:18:41.612040  1846 solver.cpp:240] Iteration 19000, loss = 0.00451508
I1205 21:18:41.612162  1846 solver.cpp:256]     Train net output #0: loss = 0.00451498 (* 1 = 0.00451498 loss)
I1205 21:18:41.612227  1846 sgd_solver.cpp:106] Iteration 19000, lr = 0.00449989
I1205 21:18:43.274453  1846 solver.cpp:240] Iteration 19100, loss = 0.00294574
I1205 21:18:43.274600  1846 solver.cpp:256]     Train net output #0: loss = 0.00294563 (* 1 = 0.00294563 loss)
I1205 21:18:43.274699  1846 sgd_solver.cpp:106] Iteration 19100, lr = 0.00448828
I1205 21:18:44.921520  1846 solver.cpp:240] Iteration 19200, loss = 0.00216401
I1205 21:18:44.921648  1846 solver.cpp:256]     Train net output #0: loss = 0.0021639 (* 1 = 0.0021639 loss)
I1205 21:18:44.921725  1846 sgd_solver.cpp:106] Iteration 19200, lr = 0.00447675
I1205 21:18:46.500147  1846 solver.cpp:240] Iteration 19300, loss = 0.00709839
I1205 21:18:46.500278  1846 solver.cpp:256]     Train net output #0: loss = 0.00709828 (* 1 = 0.00709828 loss)
I1205 21:18:46.500354  1846 sgd_solver.cpp:106] Iteration 19300, lr = 0.00446529
I1205 21:18:48.097476  1846 solver.cpp:240] Iteration 19400, loss = 0.00572969
I1205 21:18:48.097621  1846 solver.cpp:256]     Train net output #0: loss = 0.00572958 (* 1 = 0.00572958 loss)
I1205 21:18:48.097846  1846 sgd_solver.cpp:106] Iteration 19400, lr = 0.00445389
I1205 21:18:49.711591  1846 solver.cpp:349] Iteration 19500, Testing net (#0)
I1205 21:18:50.244943  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9911
I1205 21:18:50.245085  1846 solver.cpp:416]     Test net output #1: loss = 0.0291035 (* 1 = 0.0291035 loss)
I1205 21:18:50.250705  1846 solver.cpp:240] Iteration 19500, loss = 0.00272075
I1205 21:18:50.250833  1846 solver.cpp:256]     Train net output #0: loss = 0.00272065 (* 1 = 0.00272065 loss)
I1205 21:18:50.250919  1846 sgd_solver.cpp:106] Iteration 19500, lr = 0.00444256
I1205 21:18:51.907997  1846 solver.cpp:240] Iteration 19600, loss = 0.0048253
I1205 21:18:51.908177  1846 solver.cpp:256]     Train net output #0: loss = 0.0048252 (* 1 = 0.0048252 loss)
I1205 21:18:51.908263  1846 sgd_solver.cpp:106] Iteration 19600, lr = 0.0044313
I1205 21:18:53.561445  1846 solver.cpp:240] Iteration 19700, loss = 0.00176401
I1205 21:18:53.561575  1846 solver.cpp:256]     Train net output #0: loss = 0.00176391 (* 1 = 0.00176391 loss)
I1205 21:18:53.561647  1846 sgd_solver.cpp:106] Iteration 19700, lr = 0.00442011
I1205 21:18:55.226851  1846 solver.cpp:240] Iteration 19800, loss = 0.0041048
I1205 21:18:55.226995  1846 solver.cpp:256]     Train net output #0: loss = 0.0041047 (* 1 = 0.0041047 loss)
I1205 21:18:55.227072  1846 sgd_solver.cpp:106] Iteration 19800, lr = 0.00440898
I1205 21:18:56.880484  1846 solver.cpp:240] Iteration 19900, loss = 0.00124639
I1205 21:18:56.881125  1846 solver.cpp:256]     Train net output #0: loss = 0.00124628 (* 1 = 0.00124628 loss)
I1205 21:18:56.881211  1846 sgd_solver.cpp:106] Iteration 19900, lr = 0.00439791
I1205 21:18:58.518133  1846 solver.cpp:466] Snapshotting to binary proto file examples/mnist/lenet_iter_20000.caffemodel
I1205 21:18:58.575256  1846 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_20000.solverstate
I1205 21:18:58.593654  1846 solver.cpp:329] Iteration 20000, loss = 0.00682803
I1205 21:18:58.593747  1846 solver.cpp:349] Iteration 20000, Testing net (#0)
I1205 21:18:59.231370  1846 solver.cpp:416]     Test net output #0: accuracy = 0.9906
I1205 21:18:59.231523  1846 solver.cpp:416]     Test net output #1: loss = 0.0286203 (* 1 = 0.0286203 loss)
I1205 21:18:59.231575  1846 solver.cpp:334] Optimization Done.
I1205 21:18:59.231618  1846 caffe.cpp:254] Optimization Done.
