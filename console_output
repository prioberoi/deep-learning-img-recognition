ubuntu@tegra-ubuntu:~/caffe$ ./examples/mnist/train_lenet.sh
I1203 14:46:23.770792  3005 caffe.cpp:217] Using GPUs 0
I1203 14:46:23.809893  3005 caffe.cpp:222] GPU 0: NVIDIA Tegra X1
I1203 14:46:24.611987  3005 solver.cpp:60] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1203 14:46:24.612787  3005 solver.cpp:103] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I1203 14:46:24.613376  3005 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1203 14:46:24.613459  3005 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1203 14:46:24.613519  3005 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1203 14:46:24.615876  3005 layer_factory.hpp:77] Creating layer mnist
I1203 14:46:24.616968  3005 net.cpp:100] Creating Layer mnist
I1203 14:46:24.617032  3005 net.cpp:408] mnist -> data
I1203 14:46:24.617125  3005 net.cpp:408] mnist -> label
I1203 14:46:24.619688  3013 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1203 14:46:24.773879  3005 data_layer.cpp:41] output data size: 64,1,28,28
I1203 14:46:24.777117  3005 net.cpp:150] Setting up mnist
I1203 14:46:24.777186  3005 net.cpp:157] Top shape: 64 1 28 28 (50176)
I1203 14:46:24.777254  3005 net.cpp:157] Top shape: 64 (64)
I1203 14:46:24.777295  3005 net.cpp:165] Memory required for data: 200960
I1203 14:46:24.777346  3005 layer_factory.hpp:77] Creating layer conv1
I1203 14:46:24.777439  3005 net.cpp:100] Creating Layer conv1
I1203 14:46:24.777485  3005 net.cpp:434] conv1 <- data
I1203 14:46:24.777545  3005 net.cpp:408] conv1 -> conv1
I1203 14:46:26.059850  3005 net.cpp:150] Setting up conv1
I1203 14:46:26.059929  3005 net.cpp:157] Top shape: 64 20 24 24 (737280)
I1203 14:46:26.059979  3005 net.cpp:165] Memory required for data: 3150080
I1203 14:46:26.060055  3005 layer_factory.hpp:77] Creating layer pool1
I1203 14:46:26.060114  3005 net.cpp:100] Creating Layer pool1
I1203 14:46:26.060211  3005 net.cpp:434] pool1 <- conv1
I1203 14:46:26.060258  3005 net.cpp:408] pool1 -> pool1
I1203 14:46:26.060454  3005 net.cpp:150] Setting up pool1
I1203 14:46:26.060493  3005 net.cpp:157] Top shape: 64 20 12 12 (184320)
I1203 14:46:26.060533  3005 net.cpp:165] Memory required for data: 3887360
I1203 14:46:26.060570  3005 layer_factory.hpp:77] Creating layer conv2
I1203 14:46:26.060617  3005 net.cpp:100] Creating Layer conv2
I1203 14:46:26.060653  3005 net.cpp:434] conv2 <- pool1
I1203 14:46:26.060698  3005 net.cpp:408] conv2 -> conv2
I1203 14:46:26.066200  3005 net.cpp:150] Setting up conv2
I1203 14:46:26.066264  3005 net.cpp:157] Top shape: 64 50 8 8 (204800)
I1203 14:46:26.066306  3005 net.cpp:165] Memory required for data: 4706560
I1203 14:46:26.066360  3005 layer_factory.hpp:77] Creating layer pool2
I1203 14:46:26.066406  3005 net.cpp:100] Creating Layer pool2
I1203 14:46:26.066442  3005 net.cpp:434] pool2 <- conv2
I1203 14:46:26.066486  3005 net.cpp:408] pool2 -> pool2
I1203 14:46:26.066628  3005 net.cpp:150] Setting up pool2
I1203 14:46:26.066664  3005 net.cpp:157] Top shape: 64 50 4 4 (51200)
I1203 14:46:26.066704  3005 net.cpp:165] Memory required for data: 4911360
I1203 14:46:26.066736  3005 layer_factory.hpp:77] Creating layer ip1
I1203 14:46:26.066787  3005 net.cpp:100] Creating Layer ip1
I1203 14:46:26.066824  3005 net.cpp:434] ip1 <- pool2
I1203 14:46:26.066864  3005 net.cpp:408] ip1 -> ip1
I1203 14:46:26.072536  3005 net.cpp:150] Setting up ip1
I1203 14:46:26.072598  3005 net.cpp:157] Top shape: 64 500 (32000)
I1203 14:46:26.072636  3005 net.cpp:165] Memory required for data: 5039360
I1203 14:46:26.072688  3005 layer_factory.hpp:77] Creating layer relu1
I1203 14:46:26.072739  3005 net.cpp:100] Creating Layer relu1
I1203 14:46:26.072773  3005 net.cpp:434] relu1 <- ip1
I1203 14:46:26.072813  3005 net.cpp:395] relu1 -> ip1 (in-place)
I1203 14:46:26.075014  3005 net.cpp:150] Setting up relu1
I1203 14:46:26.075083  3005 net.cpp:157] Top shape: 64 500 (32000)
I1203 14:46:26.075122  3005 net.cpp:165] Memory required for data: 5167360
I1203 14:46:26.075156  3005 layer_factory.hpp:77] Creating layer ip2
I1203 14:46:26.075204  3005 net.cpp:100] Creating Layer ip2
I1203 14:46:26.075239  3005 net.cpp:434] ip2 <- ip1
I1203 14:46:26.075284  3005 net.cpp:408] ip2 -> ip2
I1203 14:46:26.076215  3005 net.cpp:150] Setting up ip2
I1203 14:46:26.076275  3005 net.cpp:157] Top shape: 64 10 (640)
I1203 14:46:26.076315  3005 net.cpp:165] Memory required for data: 5169920
I1203 14:46:26.076369  3005 layer_factory.hpp:77] Creating layer loss
I1203 14:46:26.076431  3005 net.cpp:100] Creating Layer loss
I1203 14:46:26.076472  3005 net.cpp:434] loss <- ip2
I1203 14:46:26.076513  3005 net.cpp:434] loss <- label
I1203 14:46:26.076560  3005 net.cpp:408] loss -> loss
I1203 14:46:26.076644  3005 layer_factory.hpp:77] Creating layer loss
I1203 14:46:26.078860  3005 net.cpp:150] Setting up loss
I1203 14:46:26.078923  3005 net.cpp:157] Top shape: (1)
I1203 14:46:26.078965  3005 net.cpp:160]     with loss weight 1
I1203 14:46:26.079046  3005 net.cpp:165] Memory required for data: 5169924
I1203 14:46:26.079080  3005 net.cpp:226] loss needs backward computation.
I1203 14:46:26.079125  3005 net.cpp:226] ip2 needs backward computation.
I1203 14:46:26.079155  3005 net.cpp:226] relu1 needs backward computation.
I1203 14:46:26.079183  3005 net.cpp:226] ip1 needs backward computation.
I1203 14:46:26.079228  3005 net.cpp:226] pool2 needs backward computation.
I1203 14:46:26.079259  3005 net.cpp:226] conv2 needs backward computation.
I1203 14:46:26.079290  3005 net.cpp:226] pool1 needs backward computation.
I1203 14:46:26.079325  3005 net.cpp:226] conv1 needs backward computation.
I1203 14:46:26.079355  3005 net.cpp:228] mnist does not need backward computation.
I1203 14:46:26.079383  3005 net.cpp:270] This network produces output loss
I1203 14:46:26.079428  3005 net.cpp:283] Network initialization done.
I1203 14:46:26.079974  3005 solver.cpp:193] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1203 14:46:26.080124  3005 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1203 14:46:26.080178  3005 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1203 14:46:26.082914  3005 layer_factory.hpp:77] Creating layer mnist
I1203 14:46:26.083187  3005 net.cpp:100] Creating Layer mnist
I1203 14:46:26.083238  3005 net.cpp:408] mnist -> data
I1203 14:46:26.083288  3005 net.cpp:408] mnist -> label
I1203 14:46:26.086163  3015 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1203 14:46:26.094532  3005 data_layer.cpp:41] output data size: 100,1,28,28
I1203 14:46:26.107971  3005 net.cpp:150] Setting up mnist
I1203 14:46:26.108093  3005 net.cpp:157] Top shape: 100 1 28 28 (78400)
I1203 14:46:26.108168  3005 net.cpp:157] Top shape: 100 (100)
I1203 14:46:26.108235  3005 net.cpp:165] Memory required for data: 314000
I1203 14:46:26.108299  3005 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1203 14:46:26.108382  3005 net.cpp:100] Creating Layer label_mnist_1_split
I1203 14:46:26.108453  3005 net.cpp:434] label_mnist_1_split <- label
I1203 14:46:26.108520  3005 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I1203 14:46:26.108608  3005 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I1203 14:46:26.108882  3005 net.cpp:150] Setting up label_mnist_1_split
I1203 14:46:26.108944  3005 net.cpp:157] Top shape: 100 (100)
I1203 14:46:26.109000  3005 net.cpp:157] Top shape: 100 (100)
I1203 14:46:26.109053  3005 net.cpp:165] Memory required for data: 314800
I1203 14:46:26.109112  3005 layer_factory.hpp:77] Creating layer conv1
I1203 14:46:26.109197  3005 net.cpp:100] Creating Layer conv1
I1203 14:46:26.109247  3005 net.cpp:434] conv1 <- data
I1203 14:46:26.109308  3005 net.cpp:408] conv1 -> conv1
I1203 14:46:26.120199  3005 net.cpp:150] Setting up conv1
I1203 14:46:26.120296  3005 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I1203 14:46:26.120381  3005 net.cpp:165] Memory required for data: 4922800
I1203 14:46:26.120465  3005 layer_factory.hpp:77] Creating layer pool1
I1203 14:46:26.120636  3005 net.cpp:100] Creating Layer pool1
I1203 14:46:26.120704  3005 net.cpp:434] pool1 <- conv1
I1203 14:46:26.120780  3005 net.cpp:408] pool1 -> pool1
I1203 14:46:26.121078  3005 net.cpp:150] Setting up pool1
I1203 14:46:26.121143  3005 net.cpp:157] Top shape: 100 20 12 12 (288000)
I1203 14:46:26.121206  3005 net.cpp:165] Memory required for data: 6074800
I1203 14:46:26.121258  3005 layer_factory.hpp:77] Creating layer conv2
I1203 14:46:26.121341  3005 net.cpp:100] Creating Layer conv2
I1203 14:46:26.121397  3005 net.cpp:434] conv2 <- pool1
I1203 14:46:26.121457  3005 net.cpp:408] conv2 -> conv2
I1203 14:46:26.133352  3005 net.cpp:150] Setting up conv2
I1203 14:46:26.133484  3005 net.cpp:157] Top shape: 100 50 8 8 (320000)
I1203 14:46:26.133558  3005 net.cpp:165] Memory required for data: 7354800
I1203 14:46:26.133651  3005 layer_factory.hpp:77] Creating layer pool2
I1203 14:46:26.133765  3005 net.cpp:100] Creating Layer pool2
I1203 14:46:26.133829  3005 net.cpp:434] pool2 <- conv2
I1203 14:46:26.133906  3005 net.cpp:408] pool2 -> pool2
I1203 14:46:26.134361  3005 net.cpp:150] Setting up pool2
I1203 14:46:26.134439  3005 net.cpp:157] Top shape: 100 50 4 4 (80000)
I1203 14:46:26.134500  3005 net.cpp:165] Memory required for data: 7674800
I1203 14:46:26.134553  3005 layer_factory.hpp:77] Creating layer ip1
I1203 14:46:26.134635  3005 net.cpp:100] Creating Layer ip1
I1203 14:46:26.134686  3005 net.cpp:434] ip1 <- pool2
I1203 14:46:26.134760  3005 net.cpp:408] ip1 -> ip1
I1203 14:46:26.145176  3005 net.cpp:150] Setting up ip1
I1203 14:46:26.145252  3005 net.cpp:157] Top shape: 100 500 (50000)
I1203 14:46:26.145311  3005 net.cpp:165] Memory required for data: 7874800
I1203 14:46:26.145375  3005 layer_factory.hpp:77] Creating layer relu1
I1203 14:46:26.145434  3005 net.cpp:100] Creating Layer relu1
I1203 14:46:26.145485  3005 net.cpp:434] relu1 <- ip1
I1203 14:46:26.145542  3005 net.cpp:395] relu1 -> ip1 (in-place)
I1203 14:46:26.148193  3005 net.cpp:150] Setting up relu1
I1203 14:46:26.148277  3005 net.cpp:157] Top shape: 100 500 (50000)
I1203 14:46:26.148326  3005 net.cpp:165] Memory required for data: 8074800
I1203 14:46:26.148365  3005 layer_factory.hpp:77] Creating layer ip2
I1203 14:46:26.148447  3005 net.cpp:100] Creating Layer ip2
I1203 14:46:26.148494  3005 net.cpp:434] ip2 <- ip1
I1203 14:46:26.148555  3005 net.cpp:408] ip2 -> ip2
I1203 14:46:26.149237  3005 net.cpp:150] Setting up ip2
I1203 14:46:26.149293  3005 net.cpp:157] Top shape: 100 10 (1000)
I1203 14:46:26.149343  3005 net.cpp:165] Memory required for data: 8078800
I1203 14:46:26.149401  3005 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1203 14:46:26.149449  3005 net.cpp:100] Creating Layer ip2_ip2_0_split
I1203 14:46:26.149498  3005 net.cpp:434] ip2_ip2_0_split <- ip2
I1203 14:46:26.149546  3005 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1203 14:46:26.149598  3005 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1203 14:46:26.149798  3005 net.cpp:150] Setting up ip2_ip2_0_split
I1203 14:46:26.149842  3005 net.cpp:157] Top shape: 100 10 (1000)
I1203 14:46:26.149889  3005 net.cpp:157] Top shape: 100 10 (1000)
I1203 14:46:26.149929  3005 net.cpp:165] Memory required for data: 8086800
I1203 14:46:26.149967  3005 layer_factory.hpp:77] Creating layer accuracy
I1203 14:46:26.150104  3005 net.cpp:100] Creating Layer accuracy
I1203 14:46:26.150156  3005 net.cpp:434] accuracy <- ip2_ip2_0_split_0
I1203 14:46:26.150200  3005 net.cpp:434] accuracy <- label_mnist_1_split_0
I1203 14:46:26.150255  3005 net.cpp:408] accuracy -> accuracy
I1203 14:46:26.150311  3005 net.cpp:150] Setting up accuracy
I1203 14:46:26.150349  3005 net.cpp:157] Top shape: (1)
I1203 14:46:26.150390  3005 net.cpp:165] Memory required for data: 8086804
I1203 14:46:26.150429  3005 layer_factory.hpp:77] Creating layer loss
I1203 14:46:26.150475  3005 net.cpp:100] Creating Layer loss
I1203 14:46:26.150514  3005 net.cpp:434] loss <- ip2_ip2_0_split_1
I1203 14:46:26.150557  3005 net.cpp:434] loss <- label_mnist_1_split_1
I1203 14:46:26.150666  3005 net.cpp:408] loss -> loss
I1203 14:46:26.150717  3005 layer_factory.hpp:77] Creating layer loss
I1203 14:46:26.153013  3005 net.cpp:150] Setting up loss
I1203 14:46:26.153074  3005 net.cpp:157] Top shape: (1)
I1203 14:46:26.153123  3005 net.cpp:160]     with loss weight 1
I1203 14:46:26.153173  3005 net.cpp:165] Memory required for data: 8086808
I1203 14:46:26.153220  3005 net.cpp:226] loss needs backward computation.
I1203 14:46:26.153267  3005 net.cpp:228] accuracy does not need backward computation.
I1203 14:46:26.153308  3005 net.cpp:226] ip2_ip2_0_split needs backward computation.
I1203 14:46:26.153347  3005 net.cpp:226] ip2 needs backward computation.
I1203 14:46:26.153385  3005 net.cpp:226] relu1 needs backward computation.
I1203 14:46:26.153424  3005 net.cpp:226] ip1 needs backward computation.
I1203 14:46:26.153462  3005 net.cpp:226] pool2 needs backward computation.
I1203 14:46:26.153504  3005 net.cpp:226] conv2 needs backward computation.
I1203 14:46:26.153542  3005 net.cpp:226] pool1 needs backward computation.
I1203 14:46:26.153584  3005 net.cpp:226] conv1 needs backward computation.
I1203 14:46:26.153625  3005 net.cpp:228] label_mnist_1_split does not need backward computation.
I1203 14:46:26.153668  3005 net.cpp:228] mnist does not need backward computation.
I1203 14:46:26.153705  3005 net.cpp:270] This network produces output accuracy
I1203 14:46:26.153743  3005 net.cpp:270] This network produces output loss
I1203 14:46:26.153807  3005 net.cpp:283] Network initialization done.
I1203 14:46:26.153991  3005 solver.cpp:72] Solver scaffolding done.
I1203 14:46:26.155223  3005 caffe.cpp:251] Starting Optimization
I1203 14:46:26.155275  3005 solver.cpp:291] Solving LeNet
I1203 14:46:26.155315  3005 solver.cpp:292] Learning Rate Policy: inv
I1203 14:46:26.157953  3005 solver.cpp:349] Iteration 0, Testing net (#0)
I1203 14:46:26.931439  3005 solver.cpp:416]     Test net output #0: accuracy = 0.1168
I1203 14:46:26.931581  3005 solver.cpp:416]     Test net output #1: loss = 2.35996 (* 1 = 2.35996 loss)
I1203 14:46:26.949637  3005 solver.cpp:240] Iteration 0, loss = 2.33586
I1203 14:46:26.949761  3005 solver.cpp:256]     Train net output #0: loss = 2.33586 (* 1 = 2.33586 loss)
I1203 14:46:26.949878  3005 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1203 14:46:28.476471  3005 solver.cpp:240] Iteration 100, loss = 0.221168
I1203 14:46:28.476629  3005 solver.cpp:256]     Train net output #0: loss = 0.221168 (* 1 = 0.221168 loss)
I1203 14:46:28.476743  3005 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I1203 14:46:30.002506  3005 solver.cpp:240] Iteration 200, loss = 0.160724
I1203 14:46:30.002674  3005 solver.cpp:256]     Train net output #0: loss = 0.160724 (* 1 = 0.160724 loss)
I1203 14:46:30.002777  3005 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I1203 14:46:31.620067  3005 solver.cpp:240] Iteration 300, loss = 0.193706
I1203 14:46:31.620440  3005 solver.cpp:256]     Train net output #0: loss = 0.193706 (* 1 = 0.193706 loss)
I1203 14:46:31.620667  3005 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I1203 14:46:33.173425  3005 solver.cpp:240] Iteration 400, loss = 0.0837912
I1203 14:46:33.173595  3005 solver.cpp:256]     Train net output #0: loss = 0.0837913 (* 1 = 0.0837913 loss)
I1203 14:46:33.173707  3005 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I1203 14:46:34.723608  3005 solver.cpp:349] Iteration 500, Testing net (#0)
I1203 14:46:35.236659  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9715
I1203 14:46:35.236744  3005 solver.cpp:416]     Test net output #1: loss = 0.0919688 (* 1 = 0.0919688 loss)
I1203 14:46:35.241252  3005 solver.cpp:240] Iteration 500, loss = 0.109186
I1203 14:46:35.241329  3005 solver.cpp:256]     Train net output #0: loss = 0.109186 (* 1 = 0.109186 loss)
I1203 14:46:35.241375  3005 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I1203 14:46:36.799068  3005 solver.cpp:240] Iteration 600, loss = 0.09091
I1203 14:46:36.799541  3005 solver.cpp:256]     Train net output #0: loss = 0.0909102 (* 1 = 0.0909102 loss)
I1203 14:46:36.799969  3005 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I1203 14:46:38.393237  3005 solver.cpp:240] Iteration 700, loss = 0.146029
I1203 14:46:38.393388  3005 solver.cpp:256]     Train net output #0: loss = 0.146029 (* 1 = 0.146029 loss)
I1203 14:46:38.393471  3005 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I1203 14:46:39.993445  3005 solver.cpp:240] Iteration 800, loss = 0.194866
I1203 14:46:39.993626  3005 solver.cpp:256]     Train net output #0: loss = 0.194866 (* 1 = 0.194866 loss)
I1203 14:46:39.993758  3005 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I1203 14:46:41.542330  3005 solver.cpp:240] Iteration 900, loss = 0.174632
I1203 14:46:41.542511  3005 solver.cpp:256]     Train net output #0: loss = 0.174632 (* 1 = 0.174632 loss)
I1203 14:46:41.542608  3005 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I1203 14:46:43.076572  3005 solver.cpp:349] Iteration 1000, Testing net (#0)
I1203 14:46:43.596771  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9819
I1203 14:46:43.596874  3005 solver.cpp:416]     Test net output #1: loss = 0.0572389 (* 1 = 0.0572389 loss)
I1203 14:46:43.602730  3005 solver.cpp:240] Iteration 1000, loss = 0.0693618
I1203 14:46:43.602809  3005 solver.cpp:256]     Train net output #0: loss = 0.0693619 (* 1 = 0.0693619 loss)
I1203 14:46:43.602973  3005 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I1203 14:46:45.150451  3005 solver.cpp:240] Iteration 1100, loss = 0.00731761
I1203 14:46:45.150605  3005 solver.cpp:256]     Train net output #0: loss = 0.00731766 (* 1 = 0.00731766 loss)
I1203 14:46:45.150694  3005 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I1203 14:46:46.689827  3005 solver.cpp:240] Iteration 1200, loss = 0.0152767
I1203 14:46:46.689985  3005 solver.cpp:256]     Train net output #0: loss = 0.0152767 (* 1 = 0.0152767 loss)
I1203 14:46:46.690080  3005 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I1203 14:46:48.244920  3005 solver.cpp:240] Iteration 1300, loss = 0.0152105
I1203 14:46:48.245080  3005 solver.cpp:256]     Train net output #0: loss = 0.0152105 (* 1 = 0.0152105 loss)
I1203 14:46:48.245187  3005 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I1203 14:46:49.790421  3005 solver.cpp:240] Iteration 1400, loss = 0.00750676
I1203 14:46:49.790583  3005 solver.cpp:256]     Train net output #0: loss = 0.00750678 (* 1 = 0.00750678 loss)
I1203 14:46:49.790678  3005 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I1203 14:46:51.313927  3005 solver.cpp:349] Iteration 1500, Testing net (#0)
I1203 14:46:51.829116  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9843
I1203 14:46:51.829242  3005 solver.cpp:416]     Test net output #1: loss = 0.0514264 (* 1 = 0.0514264 loss)
I1203 14:46:51.834272  3005 solver.cpp:240] Iteration 1500, loss = 0.0956916
I1203 14:46:51.834384  3005 solver.cpp:256]     Train net output #0: loss = 0.0956916 (* 1 = 0.0956916 loss)
I1203 14:46:51.834456  3005 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I1203 14:46:53.424270  3005 solver.cpp:240] Iteration 1600, loss = 0.112974
I1203 14:46:53.424394  3005 solver.cpp:256]     Train net output #0: loss = 0.112974 (* 1 = 0.112974 loss)
I1203 14:46:53.424464  3005 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I1203 14:46:54.977110  3005 solver.cpp:240] Iteration 1700, loss = 0.0359131
I1203 14:46:54.977849  3005 solver.cpp:256]     Train net output #0: loss = 0.0359131 (* 1 = 0.0359131 loss)
I1203 14:46:54.977999  3005 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I1203 14:46:56.621369  3005 solver.cpp:240] Iteration 1800, loss = 0.0407895
I1203 14:46:56.621475  3005 solver.cpp:256]     Train net output #0: loss = 0.0407895 (* 1 = 0.0407895 loss)
I1203 14:46:56.621549  3005 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I1203 14:46:58.266783  3005 solver.cpp:240] Iteration 1900, loss = 0.114715
I1203 14:46:58.266924  3005 solver.cpp:256]     Train net output #0: loss = 0.114716 (* 1 = 0.114716 loss)
I1203 14:46:58.267014  3005 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I1203 14:46:59.829556  3005 solver.cpp:349] Iteration 2000, Testing net (#0)
I1203 14:47:00.416249  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9843
I1203 14:47:00.416337  3005 solver.cpp:416]     Test net output #1: loss = 0.0488449 (* 1 = 0.0488449 loss)
I1203 14:47:00.420717  3005 solver.cpp:240] Iteration 2000, loss = 0.00991797
I1203 14:47:00.420796  3005 solver.cpp:256]     Train net output #0: loss = 0.00991806 (* 1 = 0.00991806 loss)
I1203 14:47:00.420843  3005 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I1203 14:47:02.080524  3005 solver.cpp:240] Iteration 2100, loss = 0.0252757
I1203 14:47:02.080937  3005 solver.cpp:256]     Train net output #0: loss = 0.0252758 (* 1 = 0.0252758 loss)
I1203 14:47:02.081199  3005 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I1203 14:47:03.712620  3005 solver.cpp:240] Iteration 2200, loss = 0.0153174
I1203 14:47:03.713022  3005 solver.cpp:256]     Train net output #0: loss = 0.0153175 (* 1 = 0.0153175 loss)
I1203 14:47:03.713289  3005 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I1203 14:47:05.242846  3005 solver.cpp:240] Iteration 2300, loss = 0.0816018
I1203 14:47:05.243038  3005 solver.cpp:256]     Train net output #0: loss = 0.0816019 (* 1 = 0.0816019 loss)
I1203 14:47:05.243157  3005 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I1203 14:47:06.772719  3005 solver.cpp:240] Iteration 2400, loss = 0.00860626
I1203 14:47:06.772879  3005 solver.cpp:256]     Train net output #0: loss = 0.00860636 (* 1 = 0.00860636 loss)
I1203 14:47:06.772989  3005 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I1203 14:47:08.298991  3005 solver.cpp:349] Iteration 2500, Testing net (#0)
I1203 14:47:08.859118  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9839
I1203 14:47:08.859251  3005 solver.cpp:416]     Test net output #1: loss = 0.0501641 (* 1 = 0.0501641 loss)
I1203 14:47:08.866080  3005 solver.cpp:240] Iteration 2500, loss = 0.0369441
I1203 14:47:08.866204  3005 solver.cpp:256]     Train net output #0: loss = 0.0369441 (* 1 = 0.0369441 loss)
I1203 14:47:08.866294  3005 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I1203 14:47:10.426270  3005 solver.cpp:240] Iteration 2600, loss = 0.0607489
I1203 14:47:10.426430  3005 solver.cpp:256]     Train net output #0: loss = 0.060749 (* 1 = 0.060749 loss)
I1203 14:47:10.426535  3005 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I1203 14:47:11.985388  3005 solver.cpp:240] Iteration 2700, loss = 0.0655387
I1203 14:47:11.985749  3005 solver.cpp:256]     Train net output #0: loss = 0.0655388 (* 1 = 0.0655388 loss)
I1203 14:47:11.985980  3005 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I1203 14:47:13.555485  3005 solver.cpp:240] Iteration 2800, loss = 0.00161781
I1203 14:47:13.555654  3005 solver.cpp:256]     Train net output #0: loss = 0.00161794 (* 1 = 0.00161794 loss)
I1203 14:47:13.555749  3005 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I1203 14:47:15.148416  3005 solver.cpp:240] Iteration 2900, loss = 0.0155937
I1203 14:47:15.148550  3005 solver.cpp:256]     Train net output #0: loss = 0.0155938 (* 1 = 0.0155938 loss)
I1203 14:47:15.148625  3005 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I1203 14:47:16.676699  3005 solver.cpp:349] Iteration 3000, Testing net (#0)
I1203 14:47:17.238704  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9861
I1203 14:47:17.238816  3005 solver.cpp:416]     Test net output #1: loss = 0.0425204 (* 1 = 0.0425204 loss)
I1203 14:47:17.245394  3005 solver.cpp:240] Iteration 3000, loss = 0.00898712
I1203 14:47:17.245532  3005 solver.cpp:256]     Train net output #0: loss = 0.00898723 (* 1 = 0.00898723 loss)
I1203 14:47:17.245599  3005 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I1203 14:47:18.792845  3005 solver.cpp:240] Iteration 3100, loss = 0.0398736
I1203 14:47:18.793027  3005 solver.cpp:256]     Train net output #0: loss = 0.0398737 (* 1 = 0.0398737 loss)
I1203 14:47:18.793150  3005 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I1203 14:47:20.372066  3005 solver.cpp:240] Iteration 3200, loss = 0.00977631
I1203 14:47:20.372233  3005 solver.cpp:256]     Train net output #0: loss = 0.00977642 (* 1 = 0.00977642 loss)
I1203 14:47:20.372346  3005 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I1203 14:47:21.947577  3005 solver.cpp:240] Iteration 3300, loss = 0.0391446
I1203 14:47:21.947747  3005 solver.cpp:256]     Train net output #0: loss = 0.0391447 (* 1 = 0.0391447 loss)
I1203 14:47:21.947844  3005 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I1203 14:47:23.523010  3005 solver.cpp:240] Iteration 3400, loss = 0.0139532
I1203 14:47:23.523171  3005 solver.cpp:256]     Train net output #0: loss = 0.0139533 (* 1 = 0.0139533 loss)
I1203 14:47:23.523274  3005 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I1203 14:47:25.081207  3005 solver.cpp:349] Iteration 3500, Testing net (#0)
I1203 14:47:25.620914  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9865
I1203 14:47:25.621037  3005 solver.cpp:416]     Test net output #1: loss = 0.0404505 (* 1 = 0.0404505 loss)
I1203 14:47:25.628249  3005 solver.cpp:240] Iteration 3500, loss = 0.0061665
I1203 14:47:25.628363  3005 solver.cpp:256]     Train net output #0: loss = 0.00616663 (* 1 = 0.00616663 loss)
I1203 14:47:25.628427  3005 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I1203 14:47:27.209061  3005 solver.cpp:240] Iteration 3600, loss = 0.0353787
I1203 14:47:27.209219  3005 solver.cpp:256]     Train net output #0: loss = 0.0353788 (* 1 = 0.0353788 loss)
I1203 14:47:27.209306  3005 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I1203 14:47:28.789132  3005 solver.cpp:240] Iteration 3700, loss = 0.0233748
I1203 14:47:28.789300  3005 solver.cpp:256]     Train net output #0: loss = 0.023375 (* 1 = 0.023375 loss)
I1203 14:47:28.789384  3005 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I1203 14:47:30.362671  3005 solver.cpp:240] Iteration 3800, loss = 0.013937
I1203 14:47:30.362818  3005 solver.cpp:256]     Train net output #0: loss = 0.0139371 (* 1 = 0.0139371 loss)
I1203 14:47:30.362905  3005 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I1203 14:47:31.959985  3005 solver.cpp:240] Iteration 3900, loss = 0.0338639
I1203 14:47:31.960153  3005 solver.cpp:256]     Train net output #0: loss = 0.033864 (* 1 = 0.033864 loss)
I1203 14:47:31.960253  3005 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I1203 14:47:33.487038  3005 solver.cpp:349] Iteration 4000, Testing net (#0)
I1203 14:47:34.060811  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9896
I1203 14:47:34.060930  3005 solver.cpp:416]     Test net output #1: loss = 0.0320914 (* 1 = 0.0320914 loss)
I1203 14:47:34.067077  3005 solver.cpp:240] Iteration 4000, loss = 0.0208665
I1203 14:47:34.067203  3005 solver.cpp:256]     Train net output #0: loss = 0.0208666 (* 1 = 0.0208666 loss)
I1203 14:47:34.067275  3005 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I1203 14:47:35.691597  3005 solver.cpp:240] Iteration 4100, loss = 0.0262872
I1203 14:47:35.692025  3005 solver.cpp:256]     Train net output #0: loss = 0.0262873 (* 1 = 0.0262873 loss)
I1203 14:47:35.692327  3005 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I1203 14:47:37.245147  3005 solver.cpp:240] Iteration 4200, loss = 0.00670734
I1203 14:47:37.245316  3005 solver.cpp:256]     Train net output #0: loss = 0.00670741 (* 1 = 0.00670741 loss)
I1203 14:47:37.245414  3005 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I1203 14:47:38.786352  3005 solver.cpp:240] Iteration 4300, loss = 0.0353603
I1203 14:47:38.786522  3005 solver.cpp:256]     Train net output #0: loss = 0.0353603 (* 1 = 0.0353603 loss)
I1203 14:47:38.786618  3005 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I1203 14:47:40.336485  3005 solver.cpp:240] Iteration 4400, loss = 0.0140341
I1203 14:47:40.336678  3005 solver.cpp:256]     Train net output #0: loss = 0.0140341 (* 1 = 0.0140341 loss)
I1203 14:47:40.336791  3005 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I1203 14:47:41.866807  3005 solver.cpp:349] Iteration 4500, Testing net (#0)
I1203 14:47:42.008884  3005 blocking_queue.cpp:50] Data layer prefetch queue empty
I1203 14:47:42.384747  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9884
I1203 14:47:42.384869  3005 solver.cpp:416]     Test net output #1: loss = 0.0351643 (* 1 = 0.0351643 loss)
I1203 14:47:42.390206  3005 solver.cpp:240] Iteration 4500, loss = 0.00579035
I1203 14:47:42.390328  3005 solver.cpp:256]     Train net output #0: loss = 0.00579042 (* 1 = 0.00579042 loss)
I1203 14:47:42.390409  3005 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I1203 14:47:43.930451  3005 solver.cpp:240] Iteration 4600, loss = 0.0131286
I1203 14:47:43.930609  3005 solver.cpp:256]     Train net output #0: loss = 0.0131287 (* 1 = 0.0131287 loss)
I1203 14:47:43.930728  3005 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I1203 14:47:45.507293  3005 solver.cpp:240] Iteration 4700, loss = 0.00827157
I1203 14:47:45.507673  3005 solver.cpp:256]     Train net output #0: loss = 0.00827165 (* 1 = 0.00827165 loss)
I1203 14:47:45.508111  3005 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I1203 14:47:47.062723  3005 solver.cpp:240] Iteration 4800, loss = 0.0155597
I1203 14:47:47.062901  3005 solver.cpp:256]     Train net output #0: loss = 0.0155598 (* 1 = 0.0155598 loss)
I1203 14:47:47.063010  3005 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I1203 14:47:48.613103  3005 solver.cpp:240] Iteration 4900, loss = 0.0042173
I1203 14:47:48.613273  3005 solver.cpp:256]     Train net output #0: loss = 0.00421738 (* 1 = 0.00421738 loss)
I1203 14:47:48.613394  3005 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I1203 14:47:50.170294  3005 solver.cpp:466] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I1203 14:47:50.231456  3005 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I1203 14:47:50.241660  3005 solver.cpp:349] Iteration 5000, Testing net (#0)
I1203 14:47:50.903807  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9891
I1203 14:47:50.903900  3005 solver.cpp:416]     Test net output #1: loss = 0.0319139 (* 1 = 0.0319139 loss)
I1203 14:47:50.908484  3005 solver.cpp:240] Iteration 5000, loss = 0.0333154
I1203 14:47:50.908565  3005 solver.cpp:256]     Train net output #0: loss = 0.0333155 (* 1 = 0.0333155 loss)
I1203 14:47:50.908615  3005 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I1203 14:47:52.470201  3005 solver.cpp:240] Iteration 5100, loss = 0.0149675
I1203 14:47:52.470360  3005 solver.cpp:256]     Train net output #0: loss = 0.0149676 (* 1 = 0.0149676 loss)
I1203 14:47:52.470455  3005 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I1203 14:47:53.990376  3005 solver.cpp:240] Iteration 5200, loss = 0.00506264
I1203 14:47:53.990537  3005 solver.cpp:256]     Train net output #0: loss = 0.00506271 (* 1 = 0.00506271 loss)
I1203 14:47:53.990622  3005 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I1203 14:47:55.523830  3005 solver.cpp:240] Iteration 5300, loss = 0.00153122
I1203 14:47:55.524307  3005 solver.cpp:256]     Train net output #0: loss = 0.00153128 (* 1 = 0.00153128 loss)
I1203 14:47:55.524426  3005 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I1203 14:47:57.061797  3005 solver.cpp:240] Iteration 5400, loss = 0.0100275
I1203 14:47:57.061990  3005 solver.cpp:256]     Train net output #0: loss = 0.0100276 (* 1 = 0.0100276 loss)
I1203 14:47:57.062110  3005 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I1203 14:47:58.710019  3005 solver.cpp:349] Iteration 5500, Testing net (#0)
I1203 14:47:59.482627  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9887
I1203 14:47:59.482729  3005 solver.cpp:416]     Test net output #1: loss = 0.033862 (* 1 = 0.033862 loss)
I1203 14:47:59.491070  3005 solver.cpp:240] Iteration 5500, loss = 0.00954042
I1203 14:47:59.491169  3005 solver.cpp:256]     Train net output #0: loss = 0.00954046 (* 1 = 0.00954046 loss)
I1203 14:47:59.491237  3005 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I1203 14:48:01.202441  3005 solver.cpp:240] Iteration 5600, loss = 0.00098534
I1203 14:48:01.202566  3005 solver.cpp:256]     Train net output #0: loss = 0.000985386 (* 1 = 0.000985386 loss)
I1203 14:48:01.202656  3005 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I1203 14:48:02.803542  3005 solver.cpp:240] Iteration 5700, loss = 0.00298575
I1203 14:48:02.803685  3005 solver.cpp:256]     Train net output #0: loss = 0.0029858 (* 1 = 0.0029858 loss)
I1203 14:48:02.803766  3005 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I1203 14:48:04.350368  3005 solver.cpp:240] Iteration 5800, loss = 0.0187019
I1203 14:48:04.350528  3005 solver.cpp:256]     Train net output #0: loss = 0.0187019 (* 1 = 0.0187019 loss)
I1203 14:48:04.350633  3005 sgd_solver.cpp:106] Iteration 5800, lr = 0.00709589
I1203 14:48:05.900734  3005 solver.cpp:240] Iteration 5900, loss = 0.00583408
I1203 14:48:05.900895  3005 solver.cpp:256]     Train net output #0: loss = 0.00583411 (* 1 = 0.00583411 loss)
I1203 14:48:05.901001  3005 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I1203 14:48:07.453296  3005 solver.cpp:349] Iteration 6000, Testing net (#0)
I1203 14:48:07.990645  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9904
I1203 14:48:07.990780  3005 solver.cpp:416]     Test net output #1: loss = 0.0299859 (* 1 = 0.0299859 loss)
I1203 14:48:07.996073  3005 solver.cpp:240] Iteration 6000, loss = 0.00363701
I1203 14:48:07.996186  3005 solver.cpp:256]     Train net output #0: loss = 0.00363704 (* 1 = 0.00363704 loss)
I1203 14:48:07.996263  3005 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I1203 14:48:09.634405  3005 solver.cpp:240] Iteration 6100, loss = 0.00391039
I1203 14:48:09.634552  3005 solver.cpp:256]     Train net output #0: loss = 0.00391043 (* 1 = 0.00391043 loss)
I1203 14:48:09.634634  3005 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I1203 14:48:11.294034  3005 solver.cpp:240] Iteration 6200, loss = 0.0072574
I1203 14:48:11.294183  3005 solver.cpp:256]     Train net output #0: loss = 0.00725743 (* 1 = 0.00725743 loss)
I1203 14:48:11.294286  3005 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I1203 14:48:12.884692  3005 solver.cpp:240] Iteration 6300, loss = 0.00973209
I1203 14:48:12.885011  3005 solver.cpp:256]     Train net output #0: loss = 0.00973212 (* 1 = 0.00973212 loss)
I1203 14:48:12.885217  3005 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I1203 14:48:14.409344  3005 solver.cpp:240] Iteration 6400, loss = 0.00877116
I1203 14:48:14.409512  3005 solver.cpp:256]     Train net output #0: loss = 0.00877121 (* 1 = 0.00877121 loss)
I1203 14:48:14.409611  3005 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I1203 14:48:15.922148  3005 solver.cpp:349] Iteration 6500, Testing net (#0)
I1203 14:48:16.495782  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9896
I1203 14:48:16.495898  3005 solver.cpp:416]     Test net output #1: loss = 0.0320096 (* 1 = 0.0320096 loss)
I1203 14:48:16.501175  3005 solver.cpp:240] Iteration 6500, loss = 0.011895
I1203 14:48:16.501293  3005 solver.cpp:256]     Train net output #0: loss = 0.011895 (* 1 = 0.011895 loss)
I1203 14:48:16.501454  3005 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I1203 14:48:18.036700  3005 solver.cpp:240] Iteration 6600, loss = 0.0382488
I1203 14:48:18.036854  3005 solver.cpp:256]     Train net output #0: loss = 0.0382488 (* 1 = 0.0382488 loss)
I1203 14:48:18.036944  3005 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I1203 14:48:19.563524  3005 solver.cpp:240] Iteration 6700, loss = 0.0115089
I1203 14:48:19.563696  3005 solver.cpp:256]     Train net output #0: loss = 0.011509 (* 1 = 0.011509 loss)
I1203 14:48:19.563815  3005 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I1203 14:48:21.091202  3005 solver.cpp:240] Iteration 6800, loss = 0.0038798
I1203 14:48:21.091361  3005 solver.cpp:256]     Train net output #0: loss = 0.00387984 (* 1 = 0.00387984 loss)
I1203 14:48:21.091459  3005 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I1203 14:48:22.619644  3005 solver.cpp:240] Iteration 6900, loss = 0.00451875
I1203 14:48:22.619806  3005 solver.cpp:256]     Train net output #0: loss = 0.00451878 (* 1 = 0.00451878 loss)
I1203 14:48:22.619912  3005 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I1203 14:48:24.137352  3005 solver.cpp:349] Iteration 7000, Testing net (#0)
I1203 14:48:24.658073  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9888
I1203 14:48:24.658159  3005 solver.cpp:416]     Test net output #1: loss = 0.0319214 (* 1 = 0.0319214 loss)
I1203 14:48:24.662595  3005 solver.cpp:240] Iteration 7000, loss = 0.00679528
I1203 14:48:24.662672  3005 solver.cpp:256]     Train net output #0: loss = 0.00679531 (* 1 = 0.00679531 loss)
I1203 14:48:24.662715  3005 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I1203 14:48:26.206698  3005 solver.cpp:240] Iteration 7100, loss = 0.0166141
I1203 14:48:26.207489  3005 solver.cpp:256]     Train net output #0: loss = 0.0166141 (* 1 = 0.0166141 loss)
I1203 14:48:26.207619  3005 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I1203 14:48:27.737045  3005 solver.cpp:240] Iteration 7200, loss = 0.00668024
I1203 14:48:27.737205  3005 solver.cpp:256]     Train net output #0: loss = 0.00668026 (* 1 = 0.00668026 loss)
I1203 14:48:27.737290  3005 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I1203 14:48:29.261423  3005 solver.cpp:240] Iteration 7300, loss = 0.0223468
I1203 14:48:29.261577  3005 solver.cpp:256]     Train net output #0: loss = 0.0223469 (* 1 = 0.0223469 loss)
I1203 14:48:29.261664  3005 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I1203 14:48:30.800734  3005 solver.cpp:240] Iteration 7400, loss = 0.00327753
I1203 14:48:30.800896  3005 solver.cpp:256]     Train net output #0: loss = 0.00327756 (* 1 = 0.00327756 loss)
I1203 14:48:30.801002  3005 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I1203 14:48:32.324573  3005 solver.cpp:349] Iteration 7500, Testing net (#0)
I1203 14:48:32.860296  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9897
I1203 14:48:32.860388  3005 solver.cpp:416]     Test net output #1: loss = 0.0335912 (* 1 = 0.0335912 loss)
I1203 14:48:32.865015  3005 solver.cpp:240] Iteration 7500, loss = 0.00346658
I1203 14:48:32.865098  3005 solver.cpp:256]     Train net output #0: loss = 0.0034666 (* 1 = 0.0034666 loss)
I1203 14:48:32.865150  3005 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I1203 14:48:34.411393  3005 solver.cpp:240] Iteration 7600, loss = 0.00607323
I1203 14:48:34.411852  3005 solver.cpp:256]     Train net output #0: loss = 0.00607326 (* 1 = 0.00607326 loss)
I1203 14:48:34.412153  3005 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I1203 14:48:36.052912  3005 solver.cpp:240] Iteration 7700, loss = 0.0534814
I1203 14:48:36.053087  3005 solver.cpp:256]     Train net output #0: loss = 0.0534814 (* 1 = 0.0534814 loss)
I1203 14:48:36.053207  3005 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I1203 14:48:37.632896  3005 solver.cpp:240] Iteration 7800, loss = 0.00345305
I1203 14:48:37.633066  3005 solver.cpp:256]     Train net output #0: loss = 0.00345308 (* 1 = 0.00345308 loss)
I1203 14:48:37.633162  3005 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I1203 14:48:39.205683  3005 solver.cpp:240] Iteration 7900, loss = 0.00321449
I1203 14:48:39.206094  3005 solver.cpp:256]     Train net output #0: loss = 0.00321452 (* 1 = 0.00321452 loss)
I1203 14:48:39.206359  3005 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I1203 14:48:40.801013  3005 solver.cpp:349] Iteration 8000, Testing net (#0)
I1203 14:48:41.318820  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9902
I1203 14:48:41.318910  3005 solver.cpp:416]     Test net output #1: loss = 0.0308561 (* 1 = 0.0308561 loss)
I1203 14:48:41.324563  3005 solver.cpp:240] Iteration 8000, loss = 0.00673705
I1203 14:48:41.324642  3005 solver.cpp:256]     Train net output #0: loss = 0.00673708 (* 1 = 0.00673708 loss)
I1203 14:48:41.324686  3005 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I1203 14:48:42.917332  3005 solver.cpp:240] Iteration 8100, loss = 0.0106403
I1203 14:48:42.917490  3005 solver.cpp:256]     Train net output #0: loss = 0.0106404 (* 1 = 0.0106404 loss)
I1203 14:48:42.917574  3005 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I1203 14:48:44.487568  3005 solver.cpp:240] Iteration 8200, loss = 0.00901147
I1203 14:48:44.487715  3005 solver.cpp:256]     Train net output #0: loss = 0.0090115 (* 1 = 0.0090115 loss)
I1203 14:48:44.487809  3005 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I1203 14:48:46.063210  3005 solver.cpp:240] Iteration 8300, loss = 0.0307354
I1203 14:48:46.063355  3005 solver.cpp:256]     Train net output #0: loss = 0.0307355 (* 1 = 0.0307355 loss)
I1203 14:48:46.063442  3005 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I1203 14:48:47.596866  3005 solver.cpp:240] Iteration 8400, loss = 0.00871754
I1203 14:48:47.597043  3005 solver.cpp:256]     Train net output #0: loss = 0.00871756 (* 1 = 0.00871756 loss)
I1203 14:48:47.597296  3005 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I1203 14:48:49.102864  3005 solver.cpp:349] Iteration 8500, Testing net (#0)
I1203 14:48:49.790779  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9906
I1203 14:48:49.790910  3005 solver.cpp:416]     Test net output #1: loss = 0.0300224 (* 1 = 0.0300224 loss)
I1203 14:48:49.797256  3005 solver.cpp:240] Iteration 8500, loss = 0.00673615
I1203 14:48:49.797379  3005 solver.cpp:256]     Train net output #0: loss = 0.00673618 (* 1 = 0.00673618 loss)
I1203 14:48:49.797456  3005 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I1203 14:48:51.374230  3005 solver.cpp:240] Iteration 8600, loss = 0.00058746
I1203 14:48:51.374400  3005 solver.cpp:256]     Train net output #0: loss = 0.000587482 (* 1 = 0.000587482 loss)
I1203 14:48:51.374507  3005 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I1203 14:48:52.943732  3005 solver.cpp:240] Iteration 8700, loss = 0.00348119
I1203 14:48:52.943907  3005 solver.cpp:256]     Train net output #0: loss = 0.00348121 (* 1 = 0.00348121 loss)
I1203 14:48:52.944003  3005 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I1203 14:48:54.490017  3005 solver.cpp:240] Iteration 8800, loss = 0.000907873
I1203 14:48:54.490190  3005 solver.cpp:256]     Train net output #0: loss = 0.000907895 (* 1 = 0.000907895 loss)
I1203 14:48:54.490291  3005 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I1203 14:48:56.067131  3005 solver.cpp:240] Iteration 8900, loss = 0.000762412
I1203 14:48:56.067302  3005 solver.cpp:256]     Train net output #0: loss = 0.000762435 (* 1 = 0.000762435 loss)
I1203 14:48:56.067390  3005 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I1203 14:48:57.713044  3005 solver.cpp:349] Iteration 9000, Testing net (#0)
I1203 14:48:58.279914  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9896
I1203 14:48:58.280002  3005 solver.cpp:416]     Test net output #1: loss = 0.0315167 (* 1 = 0.0315167 loss)
I1203 14:48:58.284840  3005 solver.cpp:240] Iteration 9000, loss = 0.0199867
I1203 14:48:58.284921  3005 solver.cpp:256]     Train net output #0: loss = 0.0199868 (* 1 = 0.0199868 loss)
I1203 14:48:58.284970  3005 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I1203 14:48:59.854918  3005 solver.cpp:240] Iteration 9100, loss = 0.00760476
I1203 14:48:59.855062  3005 solver.cpp:256]     Train net output #0: loss = 0.00760479 (* 1 = 0.00760479 loss)
I1203 14:48:59.855155  3005 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I1203 14:49:01.430815  3005 solver.cpp:240] Iteration 9200, loss = 0.00548336
I1203 14:49:01.430987  3005 solver.cpp:256]     Train net output #0: loss = 0.00548338 (* 1 = 0.00548338 loss)
I1203 14:49:01.431099  3005 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I1203 14:49:02.976207  3005 solver.cpp:240] Iteration 9300, loss = 0.00925557
I1203 14:49:02.976359  3005 solver.cpp:256]     Train net output #0: loss = 0.00925559 (* 1 = 0.00925559 loss)
I1203 14:49:02.976445  3005 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I1203 14:49:04.516641  3005 solver.cpp:240] Iteration 9400, loss = 0.0324463
I1203 14:49:04.516811  3005 solver.cpp:256]     Train net output #0: loss = 0.0324463 (* 1 = 0.0324463 loss)
I1203 14:49:04.516911  3005 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I1203 14:49:06.046387  3005 solver.cpp:349] Iteration 9500, Testing net (#0)
I1203 14:49:06.559291  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9889
I1203 14:49:06.559381  3005 solver.cpp:416]     Test net output #1: loss = 0.0346634 (* 1 = 0.0346634 loss)
I1203 14:49:06.563908  3005 solver.cpp:240] Iteration 9500, loss = 0.00456789
I1203 14:49:06.563989  3005 solver.cpp:256]     Train net output #0: loss = 0.00456793 (* 1 = 0.00456793 loss)
I1203 14:49:06.564031  3005 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I1203 14:49:08.193476  3005 solver.cpp:240] Iteration 9600, loss = 0.00227856
I1203 14:49:08.193847  3005 solver.cpp:256]     Train net output #0: loss = 0.00227859 (* 1 = 0.00227859 loss)
I1203 14:49:08.194082  3005 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I1203 14:49:09.754354  3005 solver.cpp:240] Iteration 9700, loss = 0.00227533
I1203 14:49:09.754490  3005 solver.cpp:256]     Train net output #0: loss = 0.00227536 (* 1 = 0.00227536 loss)
I1203 14:49:09.754566  3005 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I1203 14:49:11.316478  3005 solver.cpp:240] Iteration 9800, loss = 0.0131152
I1203 14:49:11.316635  3005 solver.cpp:256]     Train net output #0: loss = 0.0131152 (* 1 = 0.0131152 loss)
I1203 14:49:11.316721  3005 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I1203 14:49:12.930847  3005 solver.cpp:240] Iteration 9900, loss = 0.00878728
I1203 14:49:12.931007  3005 solver.cpp:256]     Train net output #0: loss = 0.00878731 (* 1 = 0.00878731 loss)
I1203 14:49:12.931138  3005 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I1203 14:49:14.497431  3005 solver.cpp:466] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I1203 14:49:14.552774  3005 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I1203 14:49:14.566581  3005 solver.cpp:329] Iteration 10000, loss = 0.00306016
I1203 14:49:14.566669  3005 solver.cpp:349] Iteration 10000, Testing net (#0)
I1203 14:49:15.147217  3005 solver.cpp:416]     Test net output #0: accuracy = 0.9905
I1203 14:49:15.147315  3005 solver.cpp:416]     Test net output #1: loss = 0.0299812 (* 1 = 0.0299812 loss)
I1203 14:49:15.147363  3005 solver.cpp:334] Optimization Done.
I1203 14:49:15.147398  3005 caffe.cpp:254] Optimization Done.

