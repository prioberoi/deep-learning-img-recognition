I1205 23:37:51.169708  3823 caffe.cpp:217] Using GPUs 0
I1205 23:37:51.180444  3823 caffe.cpp:222] GPU 0: NVIDIA Tegra X1




I1205 23:37:51.765461  3823 solver.cpp:60] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1205 23:37:51.766249  3823 solver.cpp:103] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I1205 23:37:51.766819  3823 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1205 23:37:51.766906  3823 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1205 23:37:51.766968  3823 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 40
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1205 23:37:51.768946  3823 layer_factory.hpp:77] Creating layer mnist
I1205 23:37:51.770113  3823 net.cpp:100] Creating Layer mnist
I1205 23:37:51.770182  3823 net.cpp:408] mnist -> data
I1205 23:37:51.770270  3823 net.cpp:408] mnist -> label
I1205 23:37:51.771260  3830 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1205 23:37:51.832594  3823 data_layer.cpp:41] output data size: 64,1,28,28
I1205 23:37:51.835172  3823 net.cpp:150] Setting up mnist
I1205 23:37:51.835242  3823 net.cpp:157] Top shape: 64 1 28 28 (50176)
I1205 23:37:51.835314  3823 net.cpp:157] Top shape: 64 (64)
I1205 23:37:51.835350  3823 net.cpp:165] Memory required for data: 200960
I1205 23:37:51.835402  3823 layer_factory.hpp:77] Creating layer conv1
I1205 23:37:51.835484  3823 net.cpp:100] Creating Layer conv1
I1205 23:37:51.835528  3823 net.cpp:434] conv1 <- data
I1205 23:37:51.835584  3823 net.cpp:408] conv1 -> conv1
I1205 23:37:52.631086  3823 net.cpp:150] Setting up conv1
I1205 23:37:52.631165  3823 net.cpp:157] Top shape: 64 40 24 24 (1474560)
I1205 23:37:52.631214  3823 net.cpp:165] Memory required for data: 6099200
I1205 23:37:52.631299  3823 layer_factory.hpp:77] Creating layer pool1
I1205 23:37:52.631362  3823 net.cpp:100] Creating Layer pool1
I1205 23:37:52.631484  3823 net.cpp:434] pool1 <- conv1
I1205 23:37:52.631531  3823 net.cpp:408] pool1 -> pool1
I1205 23:37:52.631711  3823 net.cpp:150] Setting up pool1
I1205 23:37:52.631752  3823 net.cpp:157] Top shape: 64 40 12 12 (368640)
I1205 23:37:52.631791  3823 net.cpp:165] Memory required for data: 7573760
I1205 23:37:52.631825  3823 layer_factory.hpp:77] Creating layer conv2
I1205 23:37:52.631872  3823 net.cpp:100] Creating Layer conv2
I1205 23:37:52.631904  3823 net.cpp:434] conv2 <- pool1
I1205 23:37:52.631945  3823 net.cpp:408] conv2 -> conv2
I1205 23:37:52.636724  3823 net.cpp:150] Setting up conv2
I1205 23:37:52.636791  3823 net.cpp:157] Top shape: 64 50 8 8 (204800)
I1205 23:37:52.636833  3823 net.cpp:165] Memory required for data: 8392960
I1205 23:37:52.636881  3823 layer_factory.hpp:77] Creating layer pool2
I1205 23:37:52.636934  3823 net.cpp:100] Creating Layer pool2
I1205 23:37:52.636970  3823 net.cpp:434] pool2 <- conv2
I1205 23:37:52.637011  3823 net.cpp:408] pool2 -> pool2
I1205 23:37:52.637197  3823 net.cpp:150] Setting up pool2
I1205 23:37:52.637238  3823 net.cpp:157] Top shape: 64 50 4 4 (51200)
I1205 23:37:52.637280  3823 net.cpp:165] Memory required for data: 8597760
I1205 23:37:52.637317  3823 layer_factory.hpp:77] Creating layer ip1
I1205 23:37:52.637367  3823 net.cpp:100] Creating Layer ip1
I1205 23:37:52.637398  3823 net.cpp:434] ip1 <- pool2
I1205 23:37:52.637440  3823 net.cpp:408] ip1 -> ip1
I1205 23:37:52.642685  3823 net.cpp:150] Setting up ip1
I1205 23:37:52.642745  3823 net.cpp:157] Top shape: 64 500 (32000)
I1205 23:37:52.642779  3823 net.cpp:165] Memory required for data: 8725760
I1205 23:37:52.642824  3823 layer_factory.hpp:77] Creating layer relu1
I1205 23:37:52.642868  3823 net.cpp:100] Creating Layer relu1
I1205 23:37:52.642899  3823 net.cpp:434] relu1 <- ip1
I1205 23:37:52.642933  3823 net.cpp:395] relu1 -> ip1 (in-place)
I1205 23:37:52.644992  3823 net.cpp:150] Setting up relu1
I1205 23:37:52.645061  3823 net.cpp:157] Top shape: 64 500 (32000)
I1205 23:37:52.645108  3823 net.cpp:165] Memory required for data: 8853760
I1205 23:37:52.645148  3823 layer_factory.hpp:77] Creating layer ip2
I1205 23:37:52.645202  3823 net.cpp:100] Creating Layer ip2
I1205 23:37:52.645241  3823 net.cpp:434] ip2 <- ip1
I1205 23:37:52.645282  3823 net.cpp:408] ip2 -> ip2
I1205 23:37:52.645881  3823 net.cpp:150] Setting up ip2
I1205 23:37:52.645939  3823 net.cpp:157] Top shape: 64 10 (640)
I1205 23:37:52.645973  3823 net.cpp:165] Memory required for data: 8856320
I1205 23:37:52.646023  3823 layer_factory.hpp:77] Creating layer loss
I1205 23:37:52.646076  3823 net.cpp:100] Creating Layer loss
I1205 23:37:52.646111  3823 net.cpp:434] loss <- ip2
I1205 23:37:52.646148  3823 net.cpp:434] loss <- label
I1205 23:37:52.646190  3823 net.cpp:408] loss -> loss
I1205 23:37:52.646261  3823 layer_factory.hpp:77] Creating layer loss
I1205 23:37:52.648298  3823 net.cpp:150] Setting up loss
I1205 23:37:52.648373  3823 net.cpp:157] Top shape: (1)
I1205 23:37:52.648425  3823 net.cpp:160]     with loss weight 1
I1205 23:37:52.648505  3823 net.cpp:165] Memory required for data: 8856324
I1205 23:37:52.648543  3823 net.cpp:226] loss needs backward computation.
I1205 23:37:52.648588  3823 net.cpp:226] ip2 needs backward computation.
I1205 23:37:52.648622  3823 net.cpp:226] relu1 needs backward computation.
I1205 23:37:52.648655  3823 net.cpp:226] ip1 needs backward computation.
I1205 23:37:52.648689  3823 net.cpp:226] pool2 needs backward computation.
I1205 23:37:52.648721  3823 net.cpp:226] conv2 needs backward computation.
I1205 23:37:52.648752  3823 net.cpp:226] pool1 needs backward computation.
I1205 23:37:52.648788  3823 net.cpp:226] conv1 needs backward computation.
I1205 23:37:52.648818  3823 net.cpp:228] mnist does not need backward computation.
I1205 23:37:52.648849  3823 net.cpp:270] This network produces output loss
I1205 23:37:52.648896  3823 net.cpp:283] Network initialization done.
I1205 23:37:52.649365  3823 solver.cpp:193] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1205 23:37:52.649535  3823 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1205 23:37:52.649596  3823 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 40
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1205 23:37:52.652046  3823 layer_factory.hpp:77] Creating layer mnist
I1205 23:37:52.652321  3823 net.cpp:100] Creating Layer mnist
I1205 23:37:52.652374  3823 net.cpp:408] mnist -> data
I1205 23:37:52.652427  3823 net.cpp:408] mnist -> label
I1205 23:37:52.653506  3832 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1205 23:37:52.653861  3823 data_layer.cpp:41] output data size: 100,1,28,28
I1205 23:37:52.658624  3823 net.cpp:150] Setting up mnist
I1205 23:37:52.658689  3823 net.cpp:157] Top shape: 100 1 28 28 (78400)
I1205 23:37:52.658735  3823 net.cpp:157] Top shape: 100 (100)
I1205 23:37:52.658771  3823 net.cpp:165] Memory required for data: 314000
I1205 23:37:52.658809  3823 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1205 23:37:52.658859  3823 net.cpp:100] Creating Layer label_mnist_1_split
I1205 23:37:52.658901  3823 net.cpp:434] label_mnist_1_split <- label
I1205 23:37:52.658949  3823 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I1205 23:37:52.659003  3823 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I1205 23:37:52.659230  3823 net.cpp:150] Setting up label_mnist_1_split
I1205 23:37:52.659283  3823 net.cpp:157] Top shape: 100 (100)
I1205 23:37:52.659322  3823 net.cpp:157] Top shape: 100 (100)
I1205 23:37:52.659355  3823 net.cpp:165] Memory required for data: 314800
I1205 23:37:52.659395  3823 layer_factory.hpp:77] Creating layer conv1
I1205 23:37:52.659449  3823 net.cpp:100] Creating Layer conv1
I1205 23:37:52.659482  3823 net.cpp:434] conv1 <- data
I1205 23:37:52.659524  3823 net.cpp:408] conv1 -> conv1
I1205 23:37:52.672664  3823 net.cpp:150] Setting up conv1
I1205 23:37:52.672746  3823 net.cpp:157] Top shape: 100 40 24 24 (2304000)
I1205 23:37:52.672806  3823 net.cpp:165] Memory required for data: 9530800
I1205 23:37:52.672866  3823 layer_factory.hpp:77] Creating layer pool1
I1205 23:37:52.672979  3823 net.cpp:100] Creating Layer pool1
I1205 23:37:52.673017  3823 net.cpp:434] pool1 <- conv1
I1205 23:37:52.673065  3823 net.cpp:408] pool1 -> pool1
I1205 23:37:52.673276  3823 net.cpp:150] Setting up pool1
I1205 23:37:52.673321  3823 net.cpp:157] Top shape: 100 40 12 12 (576000)
I1205 23:37:52.673354  3823 net.cpp:165] Memory required for data: 11834800
I1205 23:37:52.673389  3823 layer_factory.hpp:77] Creating layer conv2
I1205 23:37:52.673452  3823 net.cpp:100] Creating Layer conv2
I1205 23:37:52.673486  3823 net.cpp:434] conv2 <- pool1
I1205 23:37:52.673527  3823 net.cpp:408] conv2 -> conv2
I1205 23:37:52.680847  3823 net.cpp:150] Setting up conv2
I1205 23:37:52.680907  3823 net.cpp:157] Top shape: 100 50 8 8 (320000)
I1205 23:37:52.680953  3823 net.cpp:165] Memory required for data: 13114800
I1205 23:37:52.681033  3823 layer_factory.hpp:77] Creating layer pool2
I1205 23:37:52.681085  3823 net.cpp:100] Creating Layer pool2
I1205 23:37:52.681121  3823 net.cpp:434] pool2 <- conv2
I1205 23:37:52.681161  3823 net.cpp:408] pool2 -> pool2
I1205 23:37:52.681325  3823 net.cpp:150] Setting up pool2
I1205 23:37:52.681363  3823 net.cpp:157] Top shape: 100 50 4 4 (80000)
I1205 23:37:52.681399  3823 net.cpp:165] Memory required for data: 13434800
I1205 23:37:52.681432  3823 layer_factory.hpp:77] Creating layer ip1
I1205 23:37:52.681475  3823 net.cpp:100] Creating Layer ip1
I1205 23:37:52.681511  3823 net.cpp:434] ip1 <- pool2
I1205 23:37:52.681555  3823 net.cpp:408] ip1 -> ip1
I1205 23:37:52.686967  3823 net.cpp:150] Setting up ip1
I1205 23:37:52.687023  3823 net.cpp:157] Top shape: 100 500 (50000)
I1205 23:37:52.687058  3823 net.cpp:165] Memory required for data: 13634800
I1205 23:37:52.687144  3823 layer_factory.hpp:77] Creating layer relu1
I1205 23:37:52.687196  3823 net.cpp:100] Creating Layer relu1
I1205 23:37:52.687237  3823 net.cpp:434] relu1 <- ip1
I1205 23:37:52.687271  3823 net.cpp:395] relu1 -> ip1 (in-place)
I1205 23:37:52.688771  3823 net.cpp:150] Setting up relu1
I1205 23:37:52.688820  3823 net.cpp:157] Top shape: 100 500 (50000)
I1205 23:37:52.688884  3823 net.cpp:165] Memory required for data: 13834800
I1205 23:37:52.688937  3823 layer_factory.hpp:77] Creating layer ip2
I1205 23:37:52.689020  3823 net.cpp:100] Creating Layer ip2
I1205 23:37:52.689055  3823 net.cpp:434] ip2 <- ip1
I1205 23:37:52.689098  3823 net.cpp:408] ip2 -> ip2
I1205 23:37:52.689620  3823 net.cpp:150] Setting up ip2
I1205 23:37:52.689661  3823 net.cpp:157] Top shape: 100 10 (1000)
I1205 23:37:52.689699  3823 net.cpp:165] Memory required for data: 13838800
I1205 23:37:52.689741  3823 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1205 23:37:52.689784  3823 net.cpp:100] Creating Layer ip2_ip2_0_split
I1205 23:37:52.689817  3823 net.cpp:434] ip2_ip2_0_split <- ip2
I1205 23:37:52.689857  3823 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1205 23:37:52.689898  3823 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1205 23:37:52.690052  3823 net.cpp:150] Setting up ip2_ip2_0_split
I1205 23:37:52.690088  3823 net.cpp:157] Top shape: 100 10 (1000)
I1205 23:37:52.690124  3823 net.cpp:157] Top shape: 100 10 (1000)
I1205 23:37:52.690160  3823 net.cpp:165] Memory required for data: 13846800
I1205 23:37:52.690187  3823 layer_factory.hpp:77] Creating layer accuracy
I1205 23:37:52.690233  3823 net.cpp:100] Creating Layer accuracy
I1205 23:37:52.690268  3823 net.cpp:434] accuracy <- ip2_ip2_0_split_0
I1205 23:37:52.690304  3823 net.cpp:434] accuracy <- label_mnist_1_split_0
I1205 23:37:52.690343  3823 net.cpp:408] accuracy -> accuracy
I1205 23:37:52.690387  3823 net.cpp:150] Setting up accuracy
I1205 23:37:52.690420  3823 net.cpp:157] Top shape: (1)
I1205 23:37:52.690455  3823 net.cpp:165] Memory required for data: 13846804
I1205 23:37:52.690486  3823 layer_factory.hpp:77] Creating layer loss
I1205 23:37:52.690520  3823 net.cpp:100] Creating Layer loss
I1205 23:37:52.690557  3823 net.cpp:434] loss <- ip2_ip2_0_split_1
I1205 23:37:52.690592  3823 net.cpp:434] loss <- label_mnist_1_split_1
I1205 23:37:52.690686  3823 net.cpp:408] loss -> loss
I1205 23:37:52.690728  3823 layer_factory.hpp:77] Creating layer loss
I1205 23:37:52.692402  3823 net.cpp:150] Setting up loss
I1205 23:37:52.692451  3823 net.cpp:157] Top shape: (1)
I1205 23:37:52.692492  3823 net.cpp:160]     with loss weight 1
I1205 23:37:52.692538  3823 net.cpp:165] Memory required for data: 13846808
I1205 23:37:52.692572  3823 net.cpp:226] loss needs backward computation.
I1205 23:37:52.692605  3823 net.cpp:228] accuracy does not need backward computation.
I1205 23:37:52.692641  3823 net.cpp:226] ip2_ip2_0_split needs backward computation.
I1205 23:37:52.692675  3823 net.cpp:226] ip2 needs backward computation.
I1205 23:37:52.692710  3823 net.cpp:226] relu1 needs backward computation.
I1205 23:37:52.692744  3823 net.cpp:226] ip1 needs backward computation.
I1205 23:37:52.692775  3823 net.cpp:226] pool2 needs backward computation.
I1205 23:37:52.692808  3823 net.cpp:226] conv2 needs backward computation.
I1205 23:37:52.692842  3823 net.cpp:226] pool1 needs backward computation.
I1205 23:37:52.692872  3823 net.cpp:226] conv1 needs backward computation.
I1205 23:37:52.692903  3823 net.cpp:228] label_mnist_1_split does not need backward computation.
I1205 23:37:52.692939  3823 net.cpp:228] mnist does not need backward computation.
I1205 23:37:52.692970  3823 net.cpp:270] This network produces output accuracy
I1205 23:37:52.693006  3823 net.cpp:270] This network produces output loss
I1205 23:37:52.693068  3823 net.cpp:283] Network initialization done.
I1205 23:37:52.693217  3823 solver.cpp:72] Solver scaffolding done.
I1205 23:37:52.694284  3823 caffe.cpp:251] Starting Optimization
I1205 23:37:52.694327  3823 solver.cpp:291] Solving LeNet
I1205 23:37:52.694361  3823 solver.cpp:292] Learning Rate Policy: inv
I1205 23:37:52.695844  3823 solver.cpp:349] Iteration 0, Testing net (#0)
I1205 23:37:53.595196  3823 solver.cpp:416]     Test net output #0: accuracy = 0.064
I1205 23:37:53.595316  3823 solver.cpp:416]     Test net output #1: loss = 2.45988 (* 1 = 2.45988 loss)
I1205 23:37:53.605962  3823 solver.cpp:240] Iteration 0, loss = 2.46178
I1205 23:37:53.606088  3823 solver.cpp:256]     Train net output #0: loss = 2.46178 (* 1 = 2.46178 loss)
I1205 23:37:53.606190  3823 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1205 23:37:55.721376  3823 solver.cpp:240] Iteration 100, loss = 0.254489
I1205 23:37:55.721570  3823 solver.cpp:256]     Train net output #0: loss = 0.254489 (* 1 = 0.254489 loss)
I1205 23:37:55.721704  3823 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I1205 23:37:57.820071  3823 solver.cpp:240] Iteration 200, loss = 0.128207
I1205 23:37:57.820652  3823 solver.cpp:256]     Train net output #0: loss = 0.128207 (* 1 = 0.128207 loss)
I1205 23:37:57.821058  3823 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I1205 23:37:59.959234  3823 solver.cpp:240] Iteration 300, loss = 0.174329
I1205 23:37:59.959403  3823 solver.cpp:256]     Train net output #0: loss = 0.174329 (* 1 = 0.174329 loss)
I1205 23:37:59.959501  3823 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I1205 23:38:02.052448  3823 solver.cpp:240] Iteration 400, loss = 0.0795724
I1205 23:38:02.052645  3823 solver.cpp:256]     Train net output #0: loss = 0.0795725 (* 1 = 0.0795725 loss)
I1205 23:38:02.052778  3823 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I1205 23:38:04.086836  3823 solver.cpp:349] Iteration 500, Testing net (#0)
I1205 23:38:04.876165  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9731
I1205 23:38:04.876562  3823 solver.cpp:416]     Test net output #1: loss = 0.081282 (* 1 = 0.081282 loss)
I1205 23:38:04.887939  3823 solver.cpp:240] Iteration 500, loss = 0.106155
I1205 23:38:04.888098  3823 solver.cpp:256]     Train net output #0: loss = 0.106155 (* 1 = 0.106155 loss)
I1205 23:38:04.888187  3823 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I1205 23:38:06.986773  3823 solver.cpp:240] Iteration 600, loss = 0.088313
I1205 23:38:06.986999  3823 solver.cpp:256]     Train net output #0: loss = 0.0883131 (* 1 = 0.0883131 loss)
I1205 23:38:06.987387  3823 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I1205 23:38:09.040083  3823 solver.cpp:240] Iteration 700, loss = 0.149021
I1205 23:38:09.040266  3823 solver.cpp:256]     Train net output #0: loss = 0.149021 (* 1 = 0.149021 loss)
I1205 23:38:09.040386  3823 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I1205 23:38:11.121521  3823 solver.cpp:240] Iteration 800, loss = 0.180538
I1205 23:38:11.121755  3823 solver.cpp:256]     Train net output #0: loss = 0.180538 (* 1 = 0.180538 loss)
I1205 23:38:11.121917  3823 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I1205 23:38:13.172313  3823 solver.cpp:240] Iteration 900, loss = 0.202477
I1205 23:38:13.172513  3823 solver.cpp:256]     Train net output #0: loss = 0.202477 (* 1 = 0.202477 loss)
I1205 23:38:13.172644  3823 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I1205 23:38:15.198513  3823 solver.cpp:349] Iteration 1000, Testing net (#0)
I1205 23:38:15.981679  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9799
I1205 23:38:15.981789  3823 solver.cpp:416]     Test net output #1: loss = 0.0604797 (* 1 = 0.0604797 loss)
I1205 23:38:15.988124  3823 solver.cpp:240] Iteration 1000, loss = 0.0989008
I1205 23:38:15.988229  3823 solver.cpp:256]     Train net output #0: loss = 0.098901 (* 1 = 0.098901 loss)
I1205 23:38:15.988289  3823 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I1205 23:38:18.045900  3823 solver.cpp:240] Iteration 1100, loss = 0.00538283
I1205 23:38:18.046139  3823 solver.cpp:256]     Train net output #0: loss = 0.00538295 (* 1 = 0.00538295 loss)
I1205 23:38:18.046314  3823 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I1205 23:38:20.158083  3823 solver.cpp:240] Iteration 1200, loss = 0.019953
I1205 23:38:20.158296  3823 solver.cpp:256]     Train net output #0: loss = 0.0199531 (* 1 = 0.0199531 loss)
I1205 23:38:20.158447  3823 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I1205 23:38:22.221891  3823 solver.cpp:240] Iteration 1300, loss = 0.0155392
I1205 23:38:22.222529  3823 solver.cpp:256]     Train net output #0: loss = 0.0155394 (* 1 = 0.0155394 loss)
I1205 23:38:22.222694  3823 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I1205 23:38:24.289396  3823 solver.cpp:240] Iteration 1400, loss = 0.00844575
I1205 23:38:24.289582  3823 solver.cpp:256]     Train net output #0: loss = 0.0084459 (* 1 = 0.0084459 loss)
I1205 23:38:24.289706  3823 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I1205 23:38:26.346995  3823 solver.cpp:349] Iteration 1500, Testing net (#0)
I1205 23:38:27.138772  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9845
I1205 23:38:27.138888  3823 solver.cpp:416]     Test net output #1: loss = 0.0464457 (* 1 = 0.0464457 loss)
I1205 23:38:27.145122  3823 solver.cpp:240] Iteration 1500, loss = 0.0704353
I1205 23:38:27.145227  3823 solver.cpp:256]     Train net output #0: loss = 0.0704354 (* 1 = 0.0704354 loss)
I1205 23:38:27.145290  3823 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I1205 23:38:29.221638  3823 solver.cpp:240] Iteration 1600, loss = 0.110339
I1205 23:38:29.221868  3823 solver.cpp:256]     Train net output #0: loss = 0.110339 (* 1 = 0.110339 loss)
I1205 23:38:29.222014  3823 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I1205 23:38:31.337044  3823 solver.cpp:240] Iteration 1700, loss = 0.0253354
I1205 23:38:31.337273  3823 solver.cpp:256]     Train net output #0: loss = 0.0253356 (* 1 = 0.0253356 loss)
I1205 23:38:31.337759  3823 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I1205 23:38:33.445538  3823 solver.cpp:240] Iteration 1800, loss = 0.015106
I1205 23:38:33.445734  3823 solver.cpp:256]     Train net output #0: loss = 0.0151062 (* 1 = 0.0151062 loss)
I1205 23:38:33.445863  3823 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I1205 23:38:35.566390  3823 solver.cpp:240] Iteration 1900, loss = 0.113976
I1205 23:38:35.566591  3823 solver.cpp:256]     Train net output #0: loss = 0.113976 (* 1 = 0.113976 loss)
I1205 23:38:35.566721  3823 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I1205 23:38:37.748980  3823 solver.cpp:349] Iteration 2000, Testing net (#0)
I1205 23:38:38.550993  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9864
I1205 23:38:38.551139  3823 solver.cpp:416]     Test net output #1: loss = 0.0434459 (* 1 = 0.0434459 loss)
I1205 23:38:38.559696  3823 solver.cpp:240] Iteration 2000, loss = 0.0104478
I1205 23:38:38.559834  3823 solver.cpp:256]     Train net output #0: loss = 0.010448 (* 1 = 0.010448 loss)
I1205 23:38:38.559923  3823 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I1205 23:38:40.692222  3823 solver.cpp:240] Iteration 2100, loss = 0.0140461
I1205 23:38:40.692425  3823 solver.cpp:256]     Train net output #0: loss = 0.0140463 (* 1 = 0.0140463 loss)
I1205 23:38:40.692538  3823 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I1205 23:38:42.854228  3823 solver.cpp:240] Iteration 2200, loss = 0.0193091
I1205 23:38:42.854432  3823 solver.cpp:256]     Train net output #0: loss = 0.0193093 (* 1 = 0.0193093 loss)
I1205 23:38:42.854543  3823 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I1205 23:38:44.964639  3823 solver.cpp:240] Iteration 2300, loss = 0.0910317
I1205 23:38:44.964836  3823 solver.cpp:256]     Train net output #0: loss = 0.0910319 (* 1 = 0.0910319 loss)
I1205 23:38:44.964970  3823 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I1205 23:38:47.075244  3823 solver.cpp:240] Iteration 2400, loss = 0.0093402
I1205 23:38:47.075443  3823 solver.cpp:256]     Train net output #0: loss = 0.0093404 (* 1 = 0.0093404 loss)
I1205 23:38:47.075578  3823 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I1205 23:38:49.172883  3823 solver.cpp:349] Iteration 2500, Testing net (#0)
I1205 23:38:49.996923  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9851
I1205 23:38:49.997089  3823 solver.cpp:416]     Test net output #1: loss = 0.0452786 (* 1 = 0.0452786 loss)
I1205 23:38:50.006525  3823 solver.cpp:240] Iteration 2500, loss = 0.0697578
I1205 23:38:50.006671  3823 solver.cpp:256]     Train net output #0: loss = 0.069758 (* 1 = 0.069758 loss)
I1205 23:38:50.006904  3823 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I1205 23:38:52.148707  3823 solver.cpp:240] Iteration 2600, loss = 0.0496446
I1205 23:38:52.148902  3823 solver.cpp:256]     Train net output #0: loss = 0.0496448 (* 1 = 0.0496448 loss)
I1205 23:38:52.149018  3823 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I1205 23:38:54.258919  3823 solver.cpp:240] Iteration 2700, loss = 0.0700178
I1205 23:38:54.259764  3823 solver.cpp:256]     Train net output #0: loss = 0.070018 (* 1 = 0.070018 loss)
I1205 23:38:54.259901  3823 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I1205 23:38:56.323963  3823 solver.cpp:240] Iteration 2800, loss = 0.00148441
I1205 23:38:56.324160  3823 solver.cpp:256]     Train net output #0: loss = 0.00148457 (* 1 = 0.00148457 loss)
I1205 23:38:56.324285  3823 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I1205 23:38:58.371672  3823 solver.cpp:240] Iteration 2900, loss = 0.0203075
I1205 23:38:58.371870  3823 solver.cpp:256]     Train net output #0: loss = 0.0203077 (* 1 = 0.0203077 loss)
I1205 23:38:58.372006  3823 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I1205 23:39:00.444046  3823 solver.cpp:349] Iteration 3000, Testing net (#0)
I1205 23:39:01.225898  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9873
I1205 23:39:01.226014  3823 solver.cpp:416]     Test net output #1: loss = 0.0369581 (* 1 = 0.0369581 loss)
I1205 23:39:01.232308  3823 solver.cpp:240] Iteration 3000, loss = 0.0121441
I1205 23:39:01.232421  3823 solver.cpp:256]     Train net output #0: loss = 0.0121442 (* 1 = 0.0121442 loss)
I1205 23:39:01.232503  3823 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I1205 23:39:03.292901  3823 solver.cpp:240] Iteration 3100, loss = 0.00633661
I1205 23:39:03.293125  3823 solver.cpp:256]     Train net output #0: loss = 0.00633674 (* 1 = 0.00633674 loss)
I1205 23:39:03.293293  3823 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I1205 23:39:05.362263  3823 solver.cpp:240] Iteration 3200, loss = 0.0073969
I1205 23:39:05.362488  3823 solver.cpp:256]     Train net output #0: loss = 0.00739703 (* 1 = 0.00739703 loss)
I1205 23:39:05.362655  3823 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I1205 23:39:07.415840  3823 solver.cpp:240] Iteration 3300, loss = 0.030078
I1205 23:39:07.416034  3823 solver.cpp:256]     Train net output #0: loss = 0.0300782 (* 1 = 0.0300782 loss)
I1205 23:39:07.416163  3823 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I1205 23:39:09.488010  3823 solver.cpp:240] Iteration 3400, loss = 0.0089742
I1205 23:39:09.488265  3823 solver.cpp:256]     Train net output #0: loss = 0.00897433 (* 1 = 0.00897433 loss)
I1205 23:39:09.488627  3823 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I1205 23:39:11.590950  3823 solver.cpp:349] Iteration 3500, Testing net (#0)
I1205 23:39:12.393133  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9882
I1205 23:39:12.393446  3823 solver.cpp:416]     Test net output #1: loss = 0.0363222 (* 1 = 0.0363222 loss)
I1205 23:39:12.399976  3823 solver.cpp:240] Iteration 3500, loss = 0.00409505
I1205 23:39:12.400262  3823 solver.cpp:256]     Train net output #0: loss = 0.00409517 (* 1 = 0.00409517 loss)
I1205 23:39:12.400457  3823 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I1205 23:39:14.480696  3823 solver.cpp:240] Iteration 3600, loss = 0.0259349
I1205 23:39:14.480919  3823 solver.cpp:256]     Train net output #0: loss = 0.025935 (* 1 = 0.025935 loss)
I1205 23:39:14.481058  3823 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I1205 23:39:16.601263  3823 solver.cpp:240] Iteration 3700, loss = 0.0177535
I1205 23:39:16.601436  3823 solver.cpp:256]     Train net output #0: loss = 0.0177536 (* 1 = 0.0177536 loss)
I1205 23:39:16.601544  3823 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I1205 23:39:18.702394  3823 solver.cpp:240] Iteration 3800, loss = 0.00291033
I1205 23:39:18.702616  3823 solver.cpp:256]     Train net output #0: loss = 0.00291047 (* 1 = 0.00291047 loss)
I1205 23:39:18.702751  3823 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I1205 23:39:20.821422  3823 solver.cpp:240] Iteration 3900, loss = 0.0337103
I1205 23:39:20.821602  3823 solver.cpp:256]     Train net output #0: loss = 0.0337104 (* 1 = 0.0337104 loss)
I1205 23:39:20.821698  3823 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I1205 23:39:22.914904  3823 solver.cpp:349] Iteration 4000, Testing net (#0)
I1205 23:39:23.689610  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9901
I1205 23:39:23.689728  3823 solver.cpp:416]     Test net output #1: loss = 0.0294451 (* 1 = 0.0294451 loss)
I1205 23:39:23.696096  3823 solver.cpp:240] Iteration 4000, loss = 0.0176222
I1205 23:39:23.696207  3823 solver.cpp:256]     Train net output #0: loss = 0.0176223 (* 1 = 0.0176223 loss)
I1205 23:39:23.696269  3823 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I1205 23:39:25.787797  3823 solver.cpp:240] Iteration 4100, loss = 0.0368216
I1205 23:39:25.788269  3823 solver.cpp:256]     Train net output #0: loss = 0.0368217 (* 1 = 0.0368217 loss)
I1205 23:39:25.788417  3823 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I1205 23:39:27.852099  3823 solver.cpp:240] Iteration 4200, loss = 0.0126069
I1205 23:39:27.852315  3823 solver.cpp:256]     Train net output #0: loss = 0.012607 (* 1 = 0.012607 loss)
I1205 23:39:27.852455  3823 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I1205 23:39:29.925956  3823 solver.cpp:240] Iteration 4300, loss = 0.0582373
I1205 23:39:29.926148  3823 solver.cpp:256]     Train net output #0: loss = 0.0582374 (* 1 = 0.0582374 loss)
I1205 23:39:29.926465  3823 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I1205 23:39:32.004123  3823 solver.cpp:240] Iteration 4400, loss = 0.0199378
I1205 23:39:32.004322  3823 solver.cpp:256]     Train net output #0: loss = 0.0199379 (* 1 = 0.0199379 loss)
I1205 23:39:32.004446  3823 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I1205 23:39:34.064988  3823 solver.cpp:349] Iteration 4500, Testing net (#0)
I1205 23:39:34.882194  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9894
I1205 23:39:34.882634  3823 solver.cpp:416]     Test net output #1: loss = 0.0325689 (* 1 = 0.0325689 loss)
I1205 23:39:34.890887  3823 solver.cpp:240] Iteration 4500, loss = 0.00566315
I1205 23:39:34.891280  3823 solver.cpp:256]     Train net output #0: loss = 0.00566323 (* 1 = 0.00566323 loss)
I1205 23:39:34.891584  3823 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I1205 23:39:36.968173  3823 solver.cpp:240] Iteration 4600, loss = 0.00711258
I1205 23:39:36.968366  3823 solver.cpp:256]     Train net output #0: loss = 0.00711266 (* 1 = 0.00711266 loss)
I1205 23:39:36.968488  3823 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I1205 23:39:39.050946  3823 solver.cpp:240] Iteration 4700, loss = 0.00624834
I1205 23:39:39.051144  3823 solver.cpp:256]     Train net output #0: loss = 0.00624844 (* 1 = 0.00624844 loss)
I1205 23:39:39.051270  3823 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I1205 23:39:41.115808  3823 solver.cpp:240] Iteration 4800, loss = 0.0154082
I1205 23:39:41.116030  3823 solver.cpp:256]     Train net output #0: loss = 0.0154084 (* 1 = 0.0154084 loss)
I1205 23:39:41.116174  3823 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I1205 23:39:43.181496  3823 solver.cpp:240] Iteration 4900, loss = 0.00587444
I1205 23:39:43.181717  3823 solver.cpp:256]     Train net output #0: loss = 0.00587455 (* 1 = 0.00587455 loss)
I1205 23:39:43.181866  3823 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I1205 23:39:45.353871  3823 solver.cpp:466] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I1205 23:39:45.427008  3823 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I1205 23:39:45.441234  3823 solver.cpp:349] Iteration 5000, Testing net (#0)
I1205 23:39:46.319389  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9903
I1205 23:39:46.319831  3823 solver.cpp:416]     Test net output #1: loss = 0.0305627 (* 1 = 0.0305627 loss)
I1205 23:39:46.327626  3823 solver.cpp:240] Iteration 5000, loss = 0.0332884
I1205 23:39:46.328011  3823 solver.cpp:256]     Train net output #0: loss = 0.0332885 (* 1 = 0.0332885 loss)
I1205 23:39:46.328312  3823 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I1205 23:39:48.419116  3823 solver.cpp:240] Iteration 5100, loss = 0.021836
I1205 23:39:48.419335  3823 solver.cpp:256]     Train net output #0: loss = 0.0218361 (* 1 = 0.0218361 loss)
I1205 23:39:48.419486  3823 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I1205 23:39:50.501304  3823 solver.cpp:240] Iteration 5200, loss = 0.00982007
I1205 23:39:50.501500  3823 solver.cpp:256]     Train net output #0: loss = 0.00982019 (* 1 = 0.00982019 loss)
I1205 23:39:50.501627  3823 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I1205 23:39:52.562847  3823 solver.cpp:240] Iteration 5300, loss = 0.00305125
I1205 23:39:52.563031  3823 solver.cpp:256]     Train net output #0: loss = 0.00305135 (* 1 = 0.00305135 loss)
I1205 23:39:52.563283  3823 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I1205 23:39:54.710698  3823 solver.cpp:240] Iteration 5400, loss = 0.00777184
I1205 23:39:54.711340  3823 solver.cpp:256]     Train net output #0: loss = 0.00777194 (* 1 = 0.00777194 loss)
I1205 23:39:54.711601  3823 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I1205 23:39:56.917618  3823 solver.cpp:349] Iteration 5500, Testing net (#0)
I1205 23:39:57.729039  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9903
I1205 23:39:57.729153  3823 solver.cpp:416]     Test net output #1: loss = 0.0313027 (* 1 = 0.0313027 loss)
I1205 23:39:57.737169  3823 solver.cpp:240] Iteration 5500, loss = 0.0120138
I1205 23:39:57.737282  3823 solver.cpp:256]     Train net output #0: loss = 0.0120139 (* 1 = 0.0120139 loss)
I1205 23:39:57.737349  3823 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I1205 23:39:59.897693  3823 solver.cpp:240] Iteration 5600, loss = 0.000454862
I1205 23:39:59.898226  3823 solver.cpp:256]     Train net output #0: loss = 0.000454966 (* 1 = 0.000454966 loss)
I1205 23:39:59.898526  3823 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I1205 23:40:02.010625  3823 solver.cpp:240] Iteration 5700, loss = 0.00500358
I1205 23:40:02.010820  3823 solver.cpp:256]     Train net output #0: loss = 0.0050037 (* 1 = 0.0050037 loss)
I1205 23:40:02.010947  3823 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I1205 23:40:04.115862  3823 solver.cpp:240] Iteration 5800, loss = 0.0441302
I1205 23:40:04.116080  3823 solver.cpp:256]     Train net output #0: loss = 0.0441303 (* 1 = 0.0441303 loss)
I1205 23:40:04.116211  3823 sgd_solver.cpp:106] Iteration 5800, lr = 0.00709589
I1205 23:40:06.262989  3823 solver.cpp:240] Iteration 5900, loss = 0.00474516
I1205 23:40:06.263180  3823 solver.cpp:256]     Train net output #0: loss = 0.00474527 (* 1 = 0.00474527 loss)
I1205 23:40:06.263295  3823 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I1205 23:40:08.362768  3823 solver.cpp:349] Iteration 6000, Testing net (#0)
I1205 23:40:09.223600  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9908
I1205 23:40:09.223764  3823 solver.cpp:416]     Test net output #1: loss = 0.0269072 (* 1 = 0.0269072 loss)
I1205 23:40:09.232579  3823 solver.cpp:240] Iteration 6000, loss = 0.00259282
I1205 23:40:09.232712  3823 solver.cpp:256]     Train net output #0: loss = 0.00259293 (* 1 = 0.00259293 loss)
I1205 23:40:09.232806  3823 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I1205 23:40:11.353315  3823 solver.cpp:240] Iteration 6100, loss = 0.00432204
I1205 23:40:11.353531  3823 solver.cpp:256]     Train net output #0: loss = 0.00432214 (* 1 = 0.00432214 loss)
I1205 23:40:11.353674  3823 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I1205 23:40:13.436453  3823 solver.cpp:240] Iteration 6200, loss = 0.00579299
I1205 23:40:13.436645  3823 solver.cpp:256]     Train net output #0: loss = 0.0057931 (* 1 = 0.0057931 loss)
I1205 23:40:13.436764  3823 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I1205 23:40:15.487510  3823 solver.cpp:240] Iteration 6300, loss = 0.00936229
I1205 23:40:15.487733  3823 solver.cpp:256]     Train net output #0: loss = 0.0093624 (* 1 = 0.0093624 loss)
I1205 23:40:15.487892  3823 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I1205 23:40:17.642786  3823 solver.cpp:240] Iteration 6400, loss = 0.00643684
I1205 23:40:17.643244  3823 solver.cpp:256]     Train net output #0: loss = 0.00643695 (* 1 = 0.00643695 loss)
I1205 23:40:17.643625  3823 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I1205 23:40:19.735447  3823 solver.cpp:349] Iteration 6500, Testing net (#0)
I1205 23:40:20.731279  3823 solver.cpp:416]     Test net output #0: accuracy = 0.99
I1205 23:40:20.731417  3823 solver.cpp:416]     Test net output #1: loss = 0.0299485 (* 1 = 0.0299485 loss)
I1205 23:40:20.740981  3823 solver.cpp:240] Iteration 6500, loss = 0.0090108
I1205 23:40:20.741113  3823 solver.cpp:256]     Train net output #0: loss = 0.0090109 (* 1 = 0.0090109 loss)
I1205 23:40:20.741196  3823 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I1205 23:40:22.950824  3823 solver.cpp:240] Iteration 6600, loss = 0.0219056
I1205 23:40:22.951012  3823 solver.cpp:256]     Train net output #0: loss = 0.0219057 (* 1 = 0.0219057 loss)
I1205 23:40:22.951124  3823 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I1205 23:40:25.061700  3823 solver.cpp:240] Iteration 6700, loss = 0.00719239
I1205 23:40:25.061892  3823 solver.cpp:256]     Train net output #0: loss = 0.0071925 (* 1 = 0.0071925 loss)
I1205 23:40:25.062167  3823 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I1205 23:40:27.172986  3823 solver.cpp:240] Iteration 6800, loss = 0.00407544
I1205 23:40:27.173804  3823 solver.cpp:256]     Train net output #0: loss = 0.00407555 (* 1 = 0.00407555 loss)
I1205 23:40:27.173926  3823 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I1205 23:40:29.283161  3823 solver.cpp:240] Iteration 6900, loss = 0.00518032
I1205 23:40:29.283355  3823 solver.cpp:256]     Train net output #0: loss = 0.00518042 (* 1 = 0.00518042 loss)
I1205 23:40:29.283468  3823 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I1205 23:40:31.351851  3823 solver.cpp:349] Iteration 7000, Testing net (#0)
I1205 23:40:32.252259  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9903
I1205 23:40:32.252404  3823 solver.cpp:416]     Test net output #1: loss = 0.0282127 (* 1 = 0.0282127 loss)
I1205 23:40:32.261940  3823 solver.cpp:240] Iteration 7000, loss = 0.00491672
I1205 23:40:32.262070  3823 solver.cpp:256]     Train net output #0: loss = 0.00491682 (* 1 = 0.00491682 loss)
I1205 23:40:32.262167  3823 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I1205 23:40:34.374892  3823 solver.cpp:240] Iteration 7100, loss = 0.0135809
I1205 23:40:34.375066  3823 solver.cpp:256]     Train net output #0: loss = 0.013581 (* 1 = 0.013581 loss)
I1205 23:40:34.375174  3823 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I1205 23:40:36.468242  3823 solver.cpp:240] Iteration 7200, loss = 0.0055819
I1205 23:40:36.468425  3823 solver.cpp:256]     Train net output #0: loss = 0.00558202 (* 1 = 0.00558202 loss)
I1205 23:40:36.468536  3823 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I1205 23:40:38.575791  3823 solver.cpp:240] Iteration 7300, loss = 0.015621
I1205 23:40:38.575992  3823 solver.cpp:256]     Train net output #0: loss = 0.0156211 (* 1 = 0.0156211 loss)
I1205 23:40:38.576119  3823 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I1205 23:40:40.682651  3823 solver.cpp:240] Iteration 7400, loss = 0.00417539
I1205 23:40:40.682873  3823 solver.cpp:256]     Train net output #0: loss = 0.0041755 (* 1 = 0.0041755 loss)
I1205 23:40:40.683007  3823 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I1205 23:40:42.730650  3823 solver.cpp:349] Iteration 7500, Testing net (#0)
I1205 23:40:43.539039  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9906
I1205 23:40:43.539142  3823 solver.cpp:416]     Test net output #1: loss = 0.0300039 (* 1 = 0.0300039 loss)
I1205 23:40:43.545544  3823 solver.cpp:240] Iteration 7500, loss = 0.00184431
I1205 23:40:43.545639  3823 solver.cpp:256]     Train net output #0: loss = 0.00184442 (* 1 = 0.00184442 loss)
I1205 23:40:43.545697  3823 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I1205 23:40:45.653169  3823 solver.cpp:240] Iteration 7600, loss = 0.00457711
I1205 23:40:45.653390  3823 solver.cpp:256]     Train net output #0: loss = 0.00457721 (* 1 = 0.00457721 loss)
I1205 23:40:45.653538  3823 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I1205 23:40:47.781494  3823 solver.cpp:240] Iteration 7700, loss = 0.0331388
I1205 23:40:47.781682  3823 solver.cpp:256]     Train net output #0: loss = 0.0331389 (* 1 = 0.0331389 loss)
I1205 23:40:47.781808  3823 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I1205 23:40:49.901666  3823 solver.cpp:240] Iteration 7800, loss = 0.00421357
I1205 23:40:49.901859  3823 solver.cpp:256]     Train net output #0: loss = 0.00421368 (* 1 = 0.00421368 loss)
I1205 23:40:49.901978  3823 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I1205 23:40:51.984140  3823 solver.cpp:240] Iteration 7900, loss = 0.00439237
I1205 23:40:51.984313  3823 solver.cpp:256]     Train net output #0: loss = 0.00439248 (* 1 = 0.00439248 loss)
I1205 23:40:51.984426  3823 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I1205 23:40:54.055843  3823 solver.cpp:349] Iteration 8000, Testing net (#0)
I1205 23:40:54.871587  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9907
I1205 23:40:54.871700  3823 solver.cpp:416]     Test net output #1: loss = 0.028619 (* 1 = 0.028619 loss)
I1205 23:40:54.878538  3823 solver.cpp:240] Iteration 8000, loss = 0.0070188
I1205 23:40:54.878643  3823 solver.cpp:256]     Train net output #0: loss = 0.00701891 (* 1 = 0.00701891 loss)
I1205 23:40:54.878803  3823 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I1205 23:40:56.989410  3823 solver.cpp:240] Iteration 8100, loss = 0.0123611
I1205 23:40:56.989589  3823 solver.cpp:256]     Train net output #0: loss = 0.0123612 (* 1 = 0.0123612 loss)
I1205 23:40:56.989699  3823 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I1205 23:40:59.105298  3823 solver.cpp:240] Iteration 8200, loss = 0.0104029
I1205 23:40:59.106099  3823 solver.cpp:256]     Train net output #0: loss = 0.0104031 (* 1 = 0.0104031 loss)
I1205 23:40:59.106227  3823 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I1205 23:41:01.219594  3823 solver.cpp:240] Iteration 8300, loss = 0.02576
I1205 23:41:01.219784  3823 solver.cpp:256]     Train net output #0: loss = 0.0257601 (* 1 = 0.0257601 loss)
I1205 23:41:01.219900  3823 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I1205 23:41:03.404160  3823 solver.cpp:240] Iteration 8400, loss = 0.00990066
I1205 23:41:03.404619  3823 solver.cpp:256]     Train net output #0: loss = 0.00990076 (* 1 = 0.00990076 loss)
I1205 23:41:03.404920  3823 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I1205 23:41:05.495481  3823 solver.cpp:349] Iteration 8500, Testing net (#0)
I1205 23:41:06.292834  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9906
I1205 23:41:06.292948  3823 solver.cpp:416]     Test net output #1: loss = 0.0290321 (* 1 = 0.0290321 loss)
I1205 23:41:06.300045  3823 solver.cpp:240] Iteration 8500, loss = 0.00543657
I1205 23:41:06.300142  3823 solver.cpp:256]     Train net output #0: loss = 0.00543668 (* 1 = 0.00543668 loss)
I1205 23:41:06.300200  3823 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I1205 23:41:08.410569  3823 solver.cpp:240] Iteration 8600, loss = 0.000572289
I1205 23:41:08.410760  3823 solver.cpp:256]     Train net output #0: loss = 0.000572399 (* 1 = 0.000572399 loss)
I1205 23:41:08.410871  3823 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I1205 23:41:10.526846  3823 solver.cpp:240] Iteration 8700, loss = 0.00235604
I1205 23:41:10.527042  3823 solver.cpp:256]     Train net output #0: loss = 0.00235615 (* 1 = 0.00235615 loss)
I1205 23:41:10.527210  3823 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I1205 23:41:12.619557  3823 solver.cpp:240] Iteration 8800, loss = 0.00193538
I1205 23:41:12.619773  3823 solver.cpp:256]     Train net output #0: loss = 0.00193549 (* 1 = 0.00193549 loss)
I1205 23:41:12.619920  3823 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I1205 23:41:14.681890  3823 solver.cpp:240] Iteration 8900, loss = 0.000756593
I1205 23:41:14.682080  3823 solver.cpp:256]     Train net output #0: loss = 0.000756704 (* 1 = 0.000756704 loss)
I1205 23:41:14.682201  3823 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I1205 23:41:16.714843  3823 solver.cpp:349] Iteration 9000, Testing net (#0)
I1205 23:41:17.552935  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9906
I1205 23:41:17.553098  3823 solver.cpp:416]     Test net output #1: loss = 0.0278767 (* 1 = 0.0278767 loss)
I1205 23:41:17.561439  3823 solver.cpp:240] Iteration 9000, loss = 0.0138121
I1205 23:41:17.561594  3823 solver.cpp:256]     Train net output #0: loss = 0.0138122 (* 1 = 0.0138122 loss)
I1205 23:41:17.561710  3823 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I1205 23:41:19.675559  3823 solver.cpp:240] Iteration 9100, loss = 0.0100931
I1205 23:41:19.675755  3823 solver.cpp:256]     Train net output #0: loss = 0.0100932 (* 1 = 0.0100932 loss)
I1205 23:41:19.675887  3823 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I1205 23:41:21.744699  3823 solver.cpp:240] Iteration 9200, loss = 0.0022523
I1205 23:41:21.744897  3823 solver.cpp:256]     Train net output #0: loss = 0.00225241 (* 1 = 0.00225241 loss)
I1205 23:41:21.745033  3823 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I1205 23:41:23.898583  3823 solver.cpp:240] Iteration 9300, loss = 0.00551881
I1205 23:41:23.898756  3823 solver.cpp:256]     Train net output #0: loss = 0.00551893 (* 1 = 0.00551893 loss)
I1205 23:41:23.898854  3823 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I1205 23:41:26.016870  3823 solver.cpp:240] Iteration 9400, loss = 0.0232332
I1205 23:41:26.017061  3823 solver.cpp:256]     Train net output #0: loss = 0.0232333 (* 1 = 0.0232333 loss)
I1205 23:41:26.017223  3823 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I1205 23:41:28.203634  3823 solver.cpp:349] Iteration 9500, Testing net (#0)
I1205 23:41:29.101639  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9888
I1205 23:41:29.101899  3823 solver.cpp:416]     Test net output #1: loss = 0.0362132 (* 1 = 0.0362132 loss)
I1205 23:41:29.109654  3823 solver.cpp:240] Iteration 9500, loss = 0.00579958
I1205 23:41:29.110237  3823 solver.cpp:256]     Train net output #0: loss = 0.00579969 (* 1 = 0.00579969 loss)
I1205 23:41:29.110344  3823 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I1205 23:41:31.307021  3823 solver.cpp:240] Iteration 9600, loss = 0.00273463
I1205 23:41:31.307441  3823 solver.cpp:256]     Train net output #0: loss = 0.00273474 (* 1 = 0.00273474 loss)
I1205 23:41:31.307533  3823 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I1205 23:41:33.404781  3823 solver.cpp:240] Iteration 9700, loss = 0.00264171
I1205 23:41:33.405004  3823 solver.cpp:256]     Train net output #0: loss = 0.00264182 (* 1 = 0.00264182 loss)
I1205 23:41:33.405138  3823 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I1205 23:41:35.479512  3823 solver.cpp:240] Iteration 9800, loss = 0.0142861
I1205 23:41:35.479704  3823 solver.cpp:256]     Train net output #0: loss = 0.0142862 (* 1 = 0.0142862 loss)
I1205 23:41:35.479822  3823 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I1205 23:41:37.565665  3823 solver.cpp:240] Iteration 9900, loss = 0.00388376
I1205 23:41:37.565878  3823 solver.cpp:256]     Train net output #0: loss = 0.00388387 (* 1 = 0.00388387 loss)
I1205 23:41:37.566018  3823 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I1205 23:41:39.617849  3823 solver.cpp:466] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I1205 23:41:39.685036  3823 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I1205 23:41:39.708518  3823 solver.cpp:329] Iteration 10000, loss = 0.00323254
I1205 23:41:39.708611  3823 solver.cpp:349] Iteration 10000, Testing net (#0)
I1205 23:41:40.633229  3823 solver.cpp:416]     Test net output #0: accuracy = 0.9906
I1205 23:41:40.633610  3823 solver.cpp:416]     Test net output #1: loss = 0.0284611 (* 1 = 0.0284611 loss)
I1205 23:41:40.633865  3823 solver.cpp:334] Optimization Done.
I1205 23:41:40.634090  3823 caffe.cpp:254] Optimization Done.
